{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation of new content to users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We develop a model to give new recommendations. The algorithm needs to present twenty new previously unseen items for each user. The baseline model given to beat throws a MAP (Mean Average Precision) of 0,014. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the dataset. A data cleaning step is made in preparation for the later training step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://firebasestorage.googleapis.com/v0/b/z2tma61d2a74hya815w9x621uszb3a.appspot.com/o/RecoSys_dataset.zip?alt=media&token=46d5c550-0e95-44d7-83c5-02ffe948be75'\n",
    "local_zip = 'RecoSys_dataset.zip'\n",
    "urllib.request.urlretrieve(url, local_zip)\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>account_id</th>\n",
       "      <th>device_type</th>\n",
       "      <th>asset_id</th>\n",
       "      <th>tunein</th>\n",
       "      <th>tuneout</th>\n",
       "      <th>resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90627</td>\n",
       "      <td>STATIONARY</td>\n",
       "      <td>18332.0</td>\n",
       "      <td>2021-02-18 22:52:00.0</td>\n",
       "      <td>2021-02-18 23:35:00.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90627</td>\n",
       "      <td>STATIONARY</td>\n",
       "      <td>24727.0</td>\n",
       "      <td>2021-03-24 23:17:00.0</td>\n",
       "      <td>2021-03-25 00:01:00.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3387</td>\n",
       "      <td>STB</td>\n",
       "      <td>895.0</td>\n",
       "      <td>2021-03-15 10:05:00.0</td>\n",
       "      <td>2021-03-15 10:23:00.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3387</td>\n",
       "      <td>STB</td>\n",
       "      <td>895.0</td>\n",
       "      <td>2021-03-15 10:23:00.0</td>\n",
       "      <td>2021-03-15 11:18:00.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3387</td>\n",
       "      <td>STB</td>\n",
       "      <td>26062.0</td>\n",
       "      <td>2021-03-16 09:24:00.0</td>\n",
       "      <td>2021-03-16 09:44:00.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  account_id device_type  asset_id                 tunein  \\\n",
       "0            0       90627  STATIONARY   18332.0  2021-02-18 22:52:00.0   \n",
       "1            0       90627  STATIONARY   24727.0  2021-03-24 23:17:00.0   \n",
       "2            1        3387         STB     895.0  2021-03-15 10:05:00.0   \n",
       "3            1        3387         STB     895.0  2021-03-15 10:23:00.0   \n",
       "4            1        3387         STB   26062.0  2021-03-16 09:24:00.0   \n",
       "\n",
       "                 tuneout  resume  \n",
       "0  2021-02-18 23:35:00.0       0  \n",
       "1  2021-03-25 00:01:00.0       0  \n",
       "2  2021-03-15 10:23:00.0       0  \n",
       "3  2021-03-15 11:18:00.0       1  \n",
       "4  2021-03-16 09:44:00.0       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', sep=',')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id     0\n",
       "account_id      0\n",
       "device_type    29\n",
       "asset_id       22\n",
       "tunein          0\n",
       "tuneout         0\n",
       "resume          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>asset_id</th>\n",
       "      <th>tunein</th>\n",
       "      <th>tuneout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>90627</td>\n",
       "      <td>18332.0</td>\n",
       "      <td>2021-02-18 22:52:00.0</td>\n",
       "      <td>2021-02-18 23:35:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>90627</td>\n",
       "      <td>24727.0</td>\n",
       "      <td>2021-03-24 23:17:00.0</td>\n",
       "      <td>2021-03-25 00:01:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3387</td>\n",
       "      <td>895.0</td>\n",
       "      <td>2021-03-15 10:05:00.0</td>\n",
       "      <td>2021-03-15 10:23:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3387</td>\n",
       "      <td>895.0</td>\n",
       "      <td>2021-03-15 10:23:00.0</td>\n",
       "      <td>2021-03-15 11:18:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3387</td>\n",
       "      <td>26062.0</td>\n",
       "      <td>2021-03-16 09:24:00.0</td>\n",
       "      <td>2021-03-16 09:44:00.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_id  asset_id                 tunein                tuneout\n",
       "0       90627   18332.0  2021-02-18 22:52:00.0  2021-02-18 23:35:00.0\n",
       "1       90627   24727.0  2021-03-24 23:17:00.0  2021-03-25 00:01:00.0\n",
       "2        3387     895.0  2021-03-15 10:05:00.0  2021-03-15 10:23:00.0\n",
       "3        3387     895.0  2021-03-15 10:23:00.0  2021-03-15 11:18:00.0\n",
       "4        3387   26062.0  2021-03-16 09:24:00.0  2021-03-16 09:44:00.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop('customer_id', axis=1, inplace=False)\n",
    "train = train.drop('device_type', axis=1, inplace=False)\n",
    "train = train.drop('resume', axis=1, inplace=False)\n",
    "train = train.dropna(subset=['asset_id'], inplace=False)\n",
    "train = train.reset_index(drop=True, inplace=False)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>asset_id</th>\n",
       "      <th>tunein</th>\n",
       "      <th>tuneout</th>\n",
       "      <th>screen_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>90627</td>\n",
       "      <td>18332.0</td>\n",
       "      <td>2021-02-18 22:52:00.0</td>\n",
       "      <td>2021-02-18 23:35:00.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>90627</td>\n",
       "      <td>24727.0</td>\n",
       "      <td>2021-03-24 23:17:00.0</td>\n",
       "      <td>2021-03-25 00:01:00.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3387</td>\n",
       "      <td>895.0</td>\n",
       "      <td>2021-03-15 10:05:00.0</td>\n",
       "      <td>2021-03-15 10:23:00.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3387</td>\n",
       "      <td>895.0</td>\n",
       "      <td>2021-03-15 10:23:00.0</td>\n",
       "      <td>2021-03-15 11:18:00.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3387</td>\n",
       "      <td>26062.0</td>\n",
       "      <td>2021-03-16 09:24:00.0</td>\n",
       "      <td>2021-03-16 09:44:00.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_id  asset_id                 tunein                tuneout  \\\n",
       "0       90627   18332.0  2021-02-18 22:52:00.0  2021-02-18 23:35:00.0   \n",
       "1       90627   24727.0  2021-03-24 23:17:00.0  2021-03-25 00:01:00.0   \n",
       "2        3387     895.0  2021-03-15 10:05:00.0  2021-03-15 10:23:00.0   \n",
       "3        3387     895.0  2021-03-15 10:23:00.0  2021-03-15 11:18:00.0   \n",
       "4        3387   26062.0  2021-03-16 09:24:00.0  2021-03-16 09:44:00.0   \n",
       "\n",
       "   screen_time  \n",
       "0         43.0  \n",
       "1         44.0  \n",
       "2         18.0  \n",
       "3         55.0  \n",
       "4         20.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tunein = train.loc[:, ['tunein']].applymap(lambda date_time:date_time[:-2]).values.flatten()\n",
    "tuneout = train.loc[:, ['tuneout']].applymap(lambda date_time:date_time[:-2]).values.flatten()\n",
    "screen_time = []\n",
    "for i in train.index:\n",
    "    diff = datetime.strptime(tuneout[i], '%Y-%m-%d %H:%M:%S') - datetime.strptime(tunein[i], '%Y-%m-%d %H:%M:%S')\n",
    "    screen_time.append(diff.total_seconds()/60)\n",
    "train.loc[:,'screen_time'] = screen_time\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>asset_id</th>\n",
       "      <th>screen_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>90627</td>\n",
       "      <td>18332.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>90627</td>\n",
       "      <td>24727.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3387</td>\n",
       "      <td>895.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3387</td>\n",
       "      <td>895.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3387</td>\n",
       "      <td>26062.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_id  asset_id  screen_time\n",
       "0       90627   18332.0         43.0\n",
       "1       90627   24727.0         44.0\n",
       "2        3387     895.0         18.0\n",
       "3        3387     895.0         55.0\n",
       "4        3387   26062.0         20.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop(['tunein', 'tuneout'], axis=1, inplace=False)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>asset_id</th>\n",
       "      <th>screen_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>90627</td>\n",
       "      <td>18332</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>90627</td>\n",
       "      <td>24727</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3387</td>\n",
       "      <td>895</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3387</td>\n",
       "      <td>895</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3387</td>\n",
       "      <td>26062</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_id  asset_id  screen_time\n",
       "0       90627     18332         43.0\n",
       "1       90627     24727         44.0\n",
       "2        3387       895         18.0\n",
       "3        3387       895         55.0\n",
       "4        3387     26062         20.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[:, ['account_id']] = train.loc[:, ['account_id']].applymap(lambda account_id:int(account_id)).values.flatten()\n",
    "train.loc[:, ['asset_id']] = train.loc[:, ['asset_id']].applymap(lambda asset_id:int(asset_id)).values.flatten()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>asset_id</th>\n",
       "      <th>screen_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6397</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13056</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15900</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29811</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>29897</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_id  asset_id  screen_time\n",
       "0           0      6397         48.0\n",
       "1           0     13056         65.0\n",
       "2           0     15900        128.0\n",
       "3           0     29811         79.0\n",
       "4           0     29897         16.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.groupby(by=['account_id', 'asset_id'])['screen_time'].sum().reset_index()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113880"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train.loc[:,'account_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the metadata provided. A data cleaning step is also made. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>title</th>\n",
       "      <th>reduced_title</th>\n",
       "      <th>episode_title</th>\n",
       "      <th>show_type</th>\n",
       "      <th>released_year</th>\n",
       "      <th>country_of_origin</th>\n",
       "      <th>category</th>\n",
       "      <th>keywords</th>\n",
       "      <th>...</th>\n",
       "      <th>language_rating</th>\n",
       "      <th>dialog_rating</th>\n",
       "      <th>fv_rating</th>\n",
       "      <th>pay_per_view</th>\n",
       "      <th>pack_premium_1</th>\n",
       "      <th>pack_premium_2</th>\n",
       "      <th>create_date</th>\n",
       "      <th>modify_date</th>\n",
       "      <th>start_vod_date</th>\n",
       "      <th>end_vod_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ep:17 Tiempos Compulsivos</td>\n",
       "      <td>Tiempos_Compul_E17</td>\n",
       "      <td>Episodio 17</td>\n",
       "      <td>Serie</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>AR</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Trastornos,Médicos,Tragicómica,Telenovela,Enfe...</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>2017-12-01T10:18:15.0Z</td>\n",
       "      <td>2019-01-26T06:37:18.0Z</td>\n",
       "      <td>2017-12-01T00:00:00.0Z</td>\n",
       "      <td>2020-12-01T23:59:59.0Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7 Cajas</td>\n",
       "      <td>7_Cajas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Película</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>PY</td>\n",
       "      <td>Suspenso/Acción</td>\n",
       "      <td>Latinoamérica,Pobreza,Crimen,Pandillas</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>2017-12-19T20:58:15.0Z</td>\n",
       "      <td>2019-09-17T19:02:03.0Z</td>\n",
       "      <td>2017-12-15T00:00:00.0Z</td>\n",
       "      <td>2022-12-14T23:59:59.0Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>21939</td>\n",
       "      <td>2.0</td>\n",
       "      <td>La Maldición de las Hormigas Gigantes</td>\n",
       "      <td>La_Maldicion_de_las</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Película</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>FI</td>\n",
       "      <td>Terror/Comedia</td>\n",
       "      <td>Criaturas,Plagas,Adolescentes,Fantasía,Video J...</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>2018-02-16T13:51:07.0Z</td>\n",
       "      <td>2020-04-28T14:16:38.0Z</td>\n",
       "      <td>2018-01-25T00:00:00.0Z</td>\n",
       "      <td>2020-12-01T23:59:59.0Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Una Mujer Fantástica</td>\n",
       "      <td>Una_Mujer_Fantastic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Película</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>CL</td>\n",
       "      <td>Drama</td>\n",
       "      <td>LGBT,Mujeres,Latinoamérica</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>2018-05-26T11:58:44.0Z</td>\n",
       "      <td>2019-11-15T03:00:23.0Z</td>\n",
       "      <td>2018-05-27T00:00:00.0Z</td>\n",
       "      <td>2021-04-30T23:59:59.0Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7391</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Star Trek</td>\n",
       "      <td>Star_Trek</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Película</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Ciencia Ficción/Aventura</td>\n",
       "      <td>Fantasía,Galaxia,Futurismo,Aliens,Criaturas</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>2019-05-03T20:07:24.0Z</td>\n",
       "      <td>2020-04-09T04:37:29.0Z</td>\n",
       "      <td>2019-05-02T00:00:00.0Z</td>\n",
       "      <td>2020-12-31T23:59:59.0Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   asset_id  content_id                                  title  \\\n",
       "0     15188         0.0              Ep:17 Tiempos Compulsivos   \n",
       "1     24940         1.0                                7 Cajas   \n",
       "2     21939         2.0  La Maldición de las Hormigas Gigantes   \n",
       "3      9005         3.0                   Una Mujer Fantástica   \n",
       "4      7391         4.0                              Star Trek   \n",
       "\n",
       "         reduced_title episode_title show_type  released_year  \\\n",
       "0   Tiempos_Compul_E17   Episodio 17     Serie         2012.0   \n",
       "1              7_Cajas           NaN  Película         2012.0   \n",
       "2  La_Maldicion_de_las           NaN  Película         2016.0   \n",
       "3  Una_Mujer_Fantastic           NaN  Película         2017.0   \n",
       "4            Star_Trek           NaN  Película         2009.0   \n",
       "\n",
       "  country_of_origin                  category  \\\n",
       "0                AR                     Drama   \n",
       "1                PY           Suspenso/Acción   \n",
       "2                FI            Terror/Comedia   \n",
       "3                CL                     Drama   \n",
       "4                US  Ciencia Ficción/Aventura   \n",
       "\n",
       "                                            keywords  ... language_rating  \\\n",
       "0  Trastornos,Médicos,Tragicómica,Telenovela,Enfe...  ...               N   \n",
       "1             Latinoamérica,Pobreza,Crimen,Pandillas  ...               N   \n",
       "2  Criaturas,Plagas,Adolescentes,Fantasía,Video J...  ...               N   \n",
       "3                         LGBT,Mujeres,Latinoamérica  ...               N   \n",
       "4        Fantasía,Galaxia,Futurismo,Aliens,Criaturas  ...               N   \n",
       "\n",
       "  dialog_rating fv_rating pay_per_view  pack_premium_1 pack_premium_2  \\\n",
       "0             N         N            N               N              N   \n",
       "1             N         N            Y               N              N   \n",
       "2             N         N            N               N              N   \n",
       "3             N         N            N               Y              N   \n",
       "4             N         N            Y               N              N   \n",
       "\n",
       "              create_date             modify_date          start_vod_date  \\\n",
       "0  2017-12-01T10:18:15.0Z  2019-01-26T06:37:18.0Z  2017-12-01T00:00:00.0Z   \n",
       "1  2017-12-19T20:58:15.0Z  2019-09-17T19:02:03.0Z  2017-12-15T00:00:00.0Z   \n",
       "2  2018-02-16T13:51:07.0Z  2020-04-28T14:16:38.0Z  2018-01-25T00:00:00.0Z   \n",
       "3  2018-05-26T11:58:44.0Z  2019-11-15T03:00:23.0Z  2018-05-27T00:00:00.0Z   \n",
       "4  2019-05-03T20:07:24.0Z  2020-04-09T04:37:29.0Z  2019-05-02T00:00:00.0Z   \n",
       "\n",
       "             end_vod_date  \n",
       "0  2020-12-01T23:59:59.0Z  \n",
       "1  2022-12-14T23:59:59.0Z  \n",
       "2  2020-12-01T23:59:59.0Z  \n",
       "3  2021-04-30T23:59:59.0Z  \n",
       "4  2020-12-31T23:59:59.0Z  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv('metadata.csv', sep=';')\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asset_id                  0\n",
       "content_id               21\n",
       "title                     0\n",
       "reduced_title             0\n",
       "episode_title          4147\n",
       "show_type                 4\n",
       "released_year             0\n",
       "country_of_origin         4\n",
       "category                  0\n",
       "keywords                  2\n",
       "description               2\n",
       "reduced_desc              0\n",
       "cast_first_name        8732\n",
       "credits_first_name    12554\n",
       "run_time_min              0\n",
       "audience                  1\n",
       "made_for_tv               0\n",
       "close_caption             0\n",
       "sex_rating                0\n",
       "violence_rating           0\n",
       "language_rating           0\n",
       "dialog_rating             0\n",
       "fv_rating                 0\n",
       "pay_per_view              0\n",
       "pack_premium_1            0\n",
       "pack_premium_2            0\n",
       "create_date               0\n",
       "modify_date               0\n",
       "start_vod_date            0\n",
       "end_vod_date              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>run_time_min</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Ep:17 Tiempos Compulsivos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>7 Cajas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>21939</td>\n",
       "      <td>2.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>La Maldición de las Hormigas Gigantes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Una Mujer Fantástica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7391</td>\n",
       "      <td>4.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>Star Trek</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   asset_id  content_id  run_time_min                                  title\n",
       "0     15188         0.0          48.0              Ep:17 Tiempos Compulsivos\n",
       "1     24940         1.0         105.0                                7 Cajas\n",
       "2     21939         2.0          82.0  La Maldición de las Hormigas Gigantes\n",
       "3      9005         3.0          99.0                   Una Mujer Fantástica\n",
       "4      7391         4.0         126.0                              Star Trek"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = metadata.loc[:,['asset_id', 'content_id', 'run_time_min', 'title']]\n",
    "metadata = metadata.dropna(subset=['content_id'], inplace=False)\n",
    "metadata = metadata.reset_index(drop=True, inplace=False)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>run_time_min</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Ep:17 Tiempos Compulsivos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>7 Cajas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>21939</td>\n",
       "      <td>2.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>La Maldición de las Hormigas Gigantes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Una Mujer Fantástica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7391</td>\n",
       "      <td>4.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>Star Trek</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   asset_id  content_id  run_time_min                                  title\n",
       "0     15188         0.0          48.0              Ep:17 Tiempos Compulsivos\n",
       "1     24940         1.0         105.0                                7 Cajas\n",
       "2     21939         2.0          82.0  La Maldición de las Hormigas Gigantes\n",
       "3      9005         3.0          99.0                   Una Mujer Fantástica\n",
       "4      7391         4.0         126.0                              Star Trek"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.loc[:,['run_time_min']] = metadata.loc[:,['run_time_min']].applymap(lambda run_time: np.nan if run_time==0. else run_time).values.flatten()\n",
    "metadata = metadata.dropna(subset=['run_time_min'], inplace=False)\n",
    "metadata = metadata.reset_index(drop=True, inplace=False)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>run_time_min</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15188</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Ep:17 Tiempos Compulsivos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24940</td>\n",
       "      <td>1</td>\n",
       "      <td>105.0</td>\n",
       "      <td>7 Cajas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>21939</td>\n",
       "      <td>2</td>\n",
       "      <td>82.0</td>\n",
       "      <td>La Maldición de las Hormigas Gigantes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9005</td>\n",
       "      <td>3</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Una Mujer Fantástica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7391</td>\n",
       "      <td>4</td>\n",
       "      <td>126.0</td>\n",
       "      <td>Star Trek</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   asset_id  content_id  run_time_min                                  title\n",
       "0     15188           0          48.0              Ep:17 Tiempos Compulsivos\n",
       "1     24940           1         105.0                                7 Cajas\n",
       "2     21939           2          82.0  La Maldición de las Hormigas Gigantes\n",
       "3      9005           3          99.0                   Una Mujer Fantástica\n",
       "4      7391           4         126.0                              Star Trek"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.loc[:, ['asset_id']] = metadata.loc[:, ['asset_id']].applymap(lambda account_id:int(account_id)).values.flatten()\n",
    "metadata.loc[:, ['content_id']] = metadata.loc[:, ['content_id']].applymap(lambda asset_id:int(asset_id)).values.flatten()\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4371"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(metadata.loc[:,'content_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the cleaning process we've just made, we perform a data preprocessing step, merging all the information we have in order to get a training dataset. We use the time spent on each content per user relative to the duration of that content as the rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>run_time_min</th>\n",
       "      <th>title</th>\n",
       "      <th>account_id</th>\n",
       "      <th>screen_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>18689</td>\n",
       "      <td>749</td>\n",
       "      <td>57.0</td>\n",
       "      <td>T:1 Ep:03 The White Princess</td>\n",
       "      <td>97018</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>25352</td>\n",
       "      <td>118</td>\n",
       "      <td>68.0</td>\n",
       "      <td>T:1 Ep:07 Presunto Culpable</td>\n",
       "      <td>59418</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29669</td>\n",
       "      <td>118</td>\n",
       "      <td>66.0</td>\n",
       "      <td>T:1 Ep:06 Presunto Culpable</td>\n",
       "      <td>58187</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1639</td>\n",
       "      <td>774</td>\n",
       "      <td>30.0</td>\n",
       "      <td>T:4 Ep:05 Sex and the City</td>\n",
       "      <td>24537</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>16292</td>\n",
       "      <td>771</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Ep:273 Huérfanas</td>\n",
       "      <td>9268</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   asset_id  content_id  run_time_min                         title  \\\n",
       "0     18689         749          57.0  T:1 Ep:03 The White Princess   \n",
       "1     25352         118          68.0   T:1 Ep:07 Presunto Culpable   \n",
       "2     29669         118          66.0   T:1 Ep:06 Presunto Culpable   \n",
       "3      1639         774          30.0    T:4 Ep:05 Sex and the City   \n",
       "4     16292         771          59.0              Ep:273 Huérfanas   \n",
       "\n",
       "   account_id  screen_time  \n",
       "0       97018         24.0  \n",
       "1       59418         15.0  \n",
       "2       58187        106.0  \n",
       "3       24537          4.0  \n",
       "4        9268         34.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_train = metadata.merge(right=train, how='inner', on='asset_id')\n",
    "metadata_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>run_time_min</th>\n",
       "      <th>title</th>\n",
       "      <th>account_id</th>\n",
       "      <th>screen_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>749</td>\n",
       "      <td>57.0</td>\n",
       "      <td>T:1 Ep:03 The White Princess</td>\n",
       "      <td>97018</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>68.0</td>\n",
       "      <td>T:1 Ep:07 Presunto Culpable</td>\n",
       "      <td>59418</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>66.0</td>\n",
       "      <td>T:1 Ep:06 Presunto Culpable</td>\n",
       "      <td>58187</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>774</td>\n",
       "      <td>30.0</td>\n",
       "      <td>T:4 Ep:05 Sex and the City</td>\n",
       "      <td>24537</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>771</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Ep:273 Huérfanas</td>\n",
       "      <td>9268</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   content_id  run_time_min                         title  account_id  \\\n",
       "0         749          57.0  T:1 Ep:03 The White Princess       97018   \n",
       "1         118          68.0   T:1 Ep:07 Presunto Culpable       59418   \n",
       "2         118          66.0   T:1 Ep:06 Presunto Culpable       58187   \n",
       "3         774          30.0    T:4 Ep:05 Sex and the City       24537   \n",
       "4         771          59.0              Ep:273 Huérfanas        9268   \n",
       "\n",
       "   screen_time  \n",
       "0         24.0  \n",
       "1         15.0  \n",
       "2        106.0  \n",
       "3          4.0  \n",
       "4         34.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_train = metadata_train.drop('asset_id', axis=1, inplace=False)\n",
    "metadata_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>account_id</th>\n",
       "      <th>run_time_min</th>\n",
       "      <th>screen_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1422</td>\n",
       "      <td>46.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1431</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5959</td>\n",
       "      <td>47.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8006</td>\n",
       "      <td>543.0</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9403</td>\n",
       "      <td>93.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   content_id  account_id  run_time_min  screen_time\n",
       "0           0        1422          46.0         56.0\n",
       "1           0        1431          47.0          4.0\n",
       "2           0        5959          47.0         21.0\n",
       "3           0        8006         543.0        134.0\n",
       "4           0        9403          93.0         69.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_train = metadata_train.groupby(by=['content_id','account_id'])['run_time_min','screen_time'].sum().reset_index()\n",
    "metadata_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>account_id</th>\n",
       "      <th>run_time_min</th>\n",
       "      <th>screen_time</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1422</td>\n",
       "      <td>46.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1431</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.085106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5959</td>\n",
       "      <td>47.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.446809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8006</td>\n",
       "      <td>543.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.246777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9403</td>\n",
       "      <td>93.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.741935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   content_id  account_id  run_time_min  screen_time   ratings\n",
       "0           0        1422          46.0         56.0  1.000000\n",
       "1           0        1431          47.0          4.0  0.085106\n",
       "2           0        5959          47.0         21.0  0.446809\n",
       "3           0        8006         543.0        134.0  0.246777\n",
       "4           0        9403          93.0         69.0  0.741935"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_train = metadata_train.loc[:, ['screen_time']].values.flatten()/metadata_train.loc[:, ['run_time_min']].values.flatten()\n",
    "metadata_train.loc[:,'ratings'] = np.minimum(ratings_train,1.)\n",
    "metadata_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1422</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1431</td>\n",
       "      <td>0</td>\n",
       "      <td>0.085106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5959</td>\n",
       "      <td>0</td>\n",
       "      <td>0.446809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8006</td>\n",
       "      <td>0</td>\n",
       "      <td>0.246777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9403</td>\n",
       "      <td>0</td>\n",
       "      <td>0.741935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_id  content_id   ratings\n",
       "0        1422           0  1.000000\n",
       "1        1431           0  0.085106\n",
       "2        5959           0  0.446809\n",
       "3        8006           0  0.246777\n",
       "4        9403           0  0.741935"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_train = metadata_train.loc[:,['account_id', 'content_id', 'ratings']]\n",
    "metadata_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we obtain the most popular content according to the ratings just calculated and display their titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2040,\n",
       " 3806,\n",
       " 3900,\n",
       " 4133,\n",
       " 1983,\n",
       " 729,\n",
       " 2942,\n",
       " 3210,\n",
       " 3381,\n",
       " 2160,\n",
       " 3598,\n",
       " 3384,\n",
       " 1020,\n",
       " 1316,\n",
       " 1462,\n",
       " 1877,\n",
       " 4362,\n",
       " 3690,\n",
       " 1971,\n",
       " 116]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = list(metadata_train.groupby(by='content_id').count().sort_values(by=['account_id'], ascending=False).index)\n",
    "top[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13944    T:1 Ep:01 This is Us\n",
      "13945    T:1 Ep:02 This is Us\n",
      "13946    T:1 Ep:03 This is Us\n",
      "13947    T:1 Ep:04 This is Us\n",
      "13948    T:1 Ep:05 This is Us\n",
      "                 ...         \n",
      "29778    T:5 Ep:07 This is Us\n",
      "30001    T:5 Ep:08 This is Us\n",
      "30213    T:5 Ep:09 This is Us\n",
      "31832    T:5 Ep:10 This is Us\n",
      "32532    T:5 Ep:11 This is Us\n",
      "Name: title, Length: 83, dtype: object\n",
      "\n",
      "28965    Cosa de minas\n",
      "Name: title, dtype: object\n",
      "\n",
      "29589    T:1 Ep:01 The Collapse\n",
      "29590    T:1 Ep:02 The Collapse\n",
      "29591    T:1 Ep:03 The Collapse\n",
      "29592    T:1 Ep:04 The Collapse\n",
      "29593    T:1 Ep:05 The Collapse\n",
      "29594    T:1 Ep:06 The Collapse\n",
      "29595    T:1 Ep:07 The Collapse\n",
      "29596    T:1 Ep:08 The Collapse\n",
      "Name: title, dtype: object\n",
      "\n",
      "31098    T:1 Ep:01 El nudo\n",
      "31099    T:1 Ep:02 El nudo\n",
      "31168    T:1 Ep:04 El nudo\n",
      "31169    T:1 Ep:07 El nudo\n",
      "31170    T:1 Ep:08 El nudo\n",
      "31171    T:1 Ep:09 El nudo\n",
      "31172    T:1 Ep:03 El nudo\n",
      "31173    T:1 Ep:05 El nudo\n",
      "31174    T:1 Ep:06 El nudo\n",
      "31175    T:1 Ep:10 El nudo\n",
      "31176    T:1 Ep:11 El nudo\n",
      "31177    T:1 Ep:12 El nudo\n",
      "31178    T:1 Ep:13 El nudo\n",
      "Name: title, dtype: object\n",
      "\n",
      "13062    T:1 Ep:04 Big Little Lies\n",
      "13063    T:1 Ep:05 Big Little Lies\n",
      "13064    T:1 Ep:06 Big Little Lies\n",
      "13065    T:1 Ep:07 Big Little Lies\n",
      "13074    T:1 Ep:01 Big Little Lies\n",
      "13075    T:1 Ep:02 Big Little Lies\n",
      "13076    T:1 Ep:03 Big Little Lies\n",
      "14049    T:1 Ep:01 Big Little Lies\n",
      "14050    T:1 Ep:04 Big Little Lies\n",
      "14051    T:1 Ep:05 Big Little Lies\n",
      "14052    T:1 Ep:02 Big Little Lies\n",
      "14053    T:1 Ep:03 Big Little Lies\n",
      "14054    T:1 Ep:07 Big Little Lies\n",
      "14055    T:1 Ep:06 Big Little Lies\n",
      "17936    T:2 Ep:01 Big Little Lies\n",
      "17980    T:2 Ep:02 Big Little Lies\n",
      "18016    T:2 Ep:03 Big Little Lies\n",
      "18049    T:2 Ep:04 Big Little Lies\n",
      "18082    T:2 Ep:05 Big Little Lies\n",
      "18105    T:2 Ep:06 Big Little Lies\n",
      "18137    T:2 Ep:07 Big Little Lies\n",
      "Name: title, dtype: object\n",
      "\n",
      "4506     T:1 Ep:03 Dime quién soy\n",
      "13077    T:1 Ep:01 Dime quién soy\n",
      "13078    T:1 Ep:02 Dime quién soy\n",
      "13079    T:1 Ep:03 Dime quién soy\n",
      "13083    T:1 Ep:05 Dime quién soy\n",
      "13084    T:1 Ep:08 Dime quién soy\n",
      "13085    T:1 Ep:04 Dime quién soy\n",
      "13086    T:1 Ep:07 Dime quién soy\n",
      "13087    T:1 Ep:09 Dime quién soy\n",
      "13094    T:1 Ep:06 Dime quién soy\n",
      "26719    T:1 Ep:01 Dime quién soy\n",
      "27110    T:1 Ep:02 Dime quién soy\n",
      "27743    T:1 Ep:03 Dime quién soy\n",
      "27744    T:1 Ep:04 Dime quién soy\n",
      "27926    T:1 Ep:05 Dime quién soy\n",
      "27938    T:1 Ep:06 Dime quién soy\n",
      "28372    T:1 Ep:07 Dime quién soy\n",
      "28733    T:1 Ep:08 Dime quién soy\n",
      "29000    T:1 Ep:09 Dime quién soy\n",
      "Name: title, dtype: object\n",
      "\n",
      "21763    T:1 Ep:01 The Outpost\n",
      "21764    T:1 Ep:02 The Outpost\n",
      "21765    T:1 Ep:03 The Outpost\n",
      "21766    T:1 Ep:04 The Outpost\n",
      "21767    T:1 Ep:05 The Outpost\n",
      "21768    T:1 Ep:08 The Outpost\n",
      "21769    T:1 Ep:06 The Outpost\n",
      "21770    T:1 Ep:07 The Outpost\n",
      "21771    T:1 Ep:09 The Outpost\n",
      "21772    T:1 Ep:10 The Outpost\n",
      "22067    T:2 Ep:02 The Outpost\n",
      "22068    T:2 Ep:01 The Outpost\n",
      "22069    T:2 Ep:03 The Outpost\n",
      "22070    T:2 Ep:05 The Outpost\n",
      "22071    T:2 Ep:06 The Outpost\n",
      "22072    T:2 Ep:10 The Outpost\n",
      "22074    T:2 Ep:08 The Outpost\n",
      "22075    T:2 Ep:09 The Outpost\n",
      "22076    T:2 Ep:11 The Outpost\n",
      "22077    T:2 Ep:12 The Outpost\n",
      "22079    T:2 Ep:04 The Outpost\n",
      "22080    T:2 Ep:13 The Outpost\n",
      "22146    T:2 Ep:07 The Outpost\n",
      "30094    T:3 Ep:01 The Outpost\n",
      "30095    T:3 Ep:02 The Outpost\n",
      "30096    T:3 Ep:03 The Outpost\n",
      "30097    T:3 Ep:04 The Outpost\n",
      "30098    T:3 Ep:05 The Outpost\n",
      "30099    T:3 Ep:06 The Outpost\n",
      "30100    T:3 Ep:07 The Outpost\n",
      "30101    T:3 Ep:08 The Outpost\n",
      "30102    T:3 Ep:09 The Outpost\n",
      "30103    T:3 Ep:10 The Outpost\n",
      "30104    T:3 Ep:11 The Outpost\n",
      "30105    T:3 Ep:12 The Outpost\n",
      "30106    T:3 Ep:13 The Outpost\n",
      "Name: title, dtype: object\n",
      "\n",
      "23873    Fuga de pretoria\n",
      "Name: title, dtype: object\n",
      "\n",
      "25541    3 metros sobre el cielo\n",
      "Name: title, dtype: object\n",
      "\n",
      "15870    T:1 Ep:01 Paw Patrol, Patrulla Canina\n",
      "15871    T:1 Ep:02 Paw Patrol, Patrulla Canina\n",
      "15872    T:1 Ep:03 Paw Patrol, Patrulla Canina\n",
      "15873    T:1 Ep:04 Paw Patrol, Patrulla Canina\n",
      "15875    T:1 Ep:05 Paw Patrol, Patrulla Canina\n",
      "15877    T:1 Ep:06 Paw Patrol, Patrulla Canina\n",
      "15878    T:1 Ep:07 Paw Patrol, Patrulla Canina\n",
      "15879    T:1 Ep:08 Paw Patrol, Patrulla Canina\n",
      "15880    T:1 Ep:09 Paw Patrol, Patrulla Canina\n",
      "15881    T:1 Ep:10 Paw Patrol, Patrulla Canina\n",
      "15882    T:1 Ep:11 Paw Patrol, Patrulla Canina\n",
      "15883    T:1 Ep:12 Paw Patrol, Patrulla Canina\n",
      "15884    T:1 Ep:13 Paw Patrol, Patrulla Canina\n",
      "15885    T:1 Ep:14 Paw Patrol, Patrulla Canina\n",
      "15886    T:1 Ep:15 Paw Patrol, Patrulla Canina\n",
      "15887    T:1 Ep:16 Paw Patrol, Patrulla Canina\n",
      "15888    T:1 Ep:17 Paw Patrol, Patrulla Canina\n",
      "15889    T:1 Ep:18 Paw Patrol, Patrulla Canina\n",
      "15890    T:1 Ep:19 Paw Patrol, Patrulla Canina\n",
      "15891    T:1 Ep:20 Paw Patrol, Patrulla Canina\n",
      "15892    T:1 Ep:21 Paw Patrol, Patrulla Canina\n",
      "15893    T:1 Ep:22 Paw Patrol, Patrulla Canina\n",
      "15894    T:1 Ep:23 Paw Patrol, Patrulla Canina\n",
      "15895    T:1 Ep:24 Paw Patrol, Patrulla Canina\n",
      "15896    T:1 Ep:25 Paw Patrol, Patrulla Canina\n",
      "15897    T:1 Ep:26 Paw Patrol, Patrulla Canina\n",
      "15898    T:2 Ep:01 Paw Patrol, Patrulla Canina\n",
      "15899    T:2 Ep:02 Paw Patrol, Patrulla Canina\n",
      "15900    T:2 Ep:03 Paw Patrol, Patrulla Canina\n",
      "15901    T:2 Ep:04 Paw Patrol, Patrulla Canina\n",
      "15902    T:2 Ep:10 Paw Patrol, Patrulla Canina\n",
      "15903    T:2 Ep:05 Paw Patrol, Patrulla Canina\n",
      "15904    T:2 Ep:06 Paw Patrol, Patrulla Canina\n",
      "15905    T:2 Ep:07 Paw Patrol, Patrulla Canina\n",
      "15906    T:2 Ep:08 Paw Patrol, Patrulla Canina\n",
      "15907    T:2 Ep:09 Paw Patrol, Patrulla Canina\n",
      "15908    T:2 Ep:11 Paw Patrol, Patrulla Canina\n",
      "15909    T:2 Ep:12 Paw Patrol, Patrulla Canina\n",
      "15910    T:2 Ep:13 Paw Patrol, Patrulla Canina\n",
      "15911    T:2 Ep:14 Paw Patrol, Patrulla Canina\n",
      "15914    T:2 Ep:15 Paw Patrol, Patrulla Canina\n",
      "15915    T:2 Ep:16 Paw Patrol, Patrulla Canina\n",
      "15916    T:2 Ep:17 Paw Patrol, Patrulla Canina\n",
      "15917    T:2 Ep:19 Paw Patrol, Patrulla Canina\n",
      "15918    T:2 Ep:18 Paw Patrol, Patrulla Canina\n",
      "15919    T:2 Ep:20 Paw Patrol, Patrulla Canina\n",
      "15920    T:2 Ep:21 Paw Patrol, Patrulla Canina\n",
      "15921    T:2 Ep:22 Paw Patrol, Patrulla Canina\n",
      "15922    T:2 Ep:23 Paw Patrol, Patrulla Canina\n",
      "15923    T:2 Ep:24 Paw Patrol, Patrulla Canina\n",
      "15924    T:2 Ep:25 Paw Patrol, Patrulla Canina\n",
      "15925    T:2 Ep:26 Paw Patrol, Patrulla Canina\n",
      "Name: title, dtype: object\n",
      "\n",
      "27663    Badur hogar\n",
      "Name: title, dtype: object\n",
      "\n",
      "25547    Tengo ganas de ti\n",
      "Name: title, dtype: object\n",
      "\n",
      "6654     01/04 - MasterChef - Celebrity\n",
      "7102     01/12 - MasterChef - Celebrity\n",
      "9392     10/05 - MasterChef - Celebrity\n",
      "9393     10/08 - MasterChef - Celebrity\n",
      "9394     10/06 - MasterChef - Celebrity\n",
      "                      ...              \n",
      "32494    03/23 - MasterChef - Celebrity\n",
      "32508    03/22 - MasterChef - Celebrity\n",
      "32606    03/24 - MasterChef - Celebrity\n",
      "32714    03/25 - MasterChef - Celebrity\n",
      "32784    03/28 - MasterChef - Celebrity\n",
      "Name: title, Length: 101, dtype: object\n",
      "\n",
      "8506     T:8 Ep:40 Peppa Pig\n",
      "8507     T:8 Ep:41 Peppa Pig\n",
      "8508     T:8 Ep:42 Peppa Pig\n",
      "8509     T:8 Ep:43 Peppa Pig\n",
      "11080    T:7 Ep:26 Peppa Pig\n",
      "11081    T:7 Ep:27 Peppa Pig\n",
      "11082    T:7 Ep:28 Peppa Pig\n",
      "12995    T:7 Ep:08 Peppa Pig\n",
      "12996    T:7 Ep:09 Peppa Pig\n",
      "13156    T:7 Ep:07 Peppa Pig\n",
      "13157    T:7 Ep:10 Peppa Pig\n",
      "13158    T:7 Ep:11 Peppa Pig\n",
      "27263    T:7 Ep:42 Peppa Pig\n",
      "27264    T:7 Ep:43 Peppa Pig\n",
      "27265    T:7 Ep:44 Peppa Pig\n",
      "30510    T:7 Ep:03 Peppa Pig\n",
      "30511    T:7 Ep:04 Peppa Pig\n",
      "30512    T:7 Ep:05 Peppa Pig\n",
      "30513    T:7 Ep:01 Peppa Pig\n",
      "30514    T:7 Ep:02 Peppa Pig\n",
      "31318    T:8 Ep:03 Peppa Pig\n",
      "31319    T:8 Ep:04 Peppa Pig\n",
      "31320    T:8 Ep:05 Peppa Pig\n",
      "31321    T:8 Ep:06 Peppa Pig\n",
      "31322    T:8 Ep:07 Peppa Pig\n",
      "31323    T:8 Ep:08 Peppa Pig\n",
      "31324    T:8 Ep:09 Peppa Pig\n",
      "32008    T:8 Ep:10 Peppa Pig\n",
      "Name: title, dtype: object\n",
      "\n",
      "9551      T:1 Ep:01 El comisario Montalbano\n",
      "9552      T:1 Ep:02 El comisario Montalbano\n",
      "9553      T:2 Ep:01 El comisario Montalbano\n",
      "9554      T:2 Ep:02 El comisario Montalbano\n",
      "9555      T:3 Ep:01 El comisario Montalbano\n",
      "                        ...                \n",
      "26734    T:12 Ep:01 El comisario Montalbano\n",
      "26740    T:11 Ep:01 El comisario Montalbano\n",
      "26757    T:13 Ep:01 El comisario Montalbano\n",
      "26816    T:14 Ep:02 El comisario Montalbano\n",
      "26897    T:14 Ep:01 El comisario Montalbano\n",
      "Name: title, Length: 72, dtype: object\n",
      "\n",
      "11735    T:17 Ep:01 Grey's Anatomy\n",
      "12675    T:17 Ep:02 Grey's Anatomy\n",
      "12845    T:17 Ep:03 Grey's Anatomy\n",
      "30732    T:17 Ep:04 Grey's Anatomy\n",
      "31203    T:17 Ep:05 Grey's Anatomy\n",
      "31853    T:17 Ep:06 Grey's Anatomy\n",
      "Name: title, dtype: object\n",
      "\n",
      "32901    Los sonámbulos\n",
      "Name: title, dtype: object\n",
      "\n",
      "28153    Rosseshow: La atípica familia tipo\n",
      "Name: title, dtype: object\n",
      "\n",
      "12773    Las aventuras del doctor Dolittle\n",
      "31943    Las aventuras del doctor Dolittle\n",
      "Name: title, dtype: object\n",
      "\n",
      "341      T:1 Ep:04 The Undoing\n",
      "23839    T:1 Ep:01 The Undoing\n",
      "24182    T:1 Ep:02 The Undoing\n",
      "24670    T:1 Ep:03 The Undoing\n",
      "25467    T:1 Ep:05 The Undoing\n",
      "26338    T:1 Ep:06 The Undoing\n",
      "26504    T:1 Ep:04 The Undoing\n",
      "Name: title, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in top[:20]:\n",
    "    print(metadata.query('content_id == {}'.format(i)).title)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the dataset for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = metadata_train.loc[:,['account_id', 'content_id']].values\n",
    "Y_train = metadata_train.loc[:,['ratings']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the model to train. We will use collaborative filtering. It is done in pure TensorFlow because the version built with Keras was perfoming much worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding():\n",
    "    \n",
    "    def __init__(self, input_dim, rank):\n",
    "        self.input_dim = input_dim\n",
    "        self.rank = rank\n",
    "        self.build()\n",
    "        \n",
    "    def add_weight(self, shape):\n",
    "        w_init = tf.random.normal(shape=shape, mean=0.0, stddev=0.05, dtype=\"float32\")\n",
    "        return tf.Variable(initial_value=w_init, trainable=True)\n",
    "        \n",
    "    def build(self):\n",
    "        self.w = self.add_weight(shape=(self.input_dim,self.rank))\n",
    "        self.weights = [self.w]\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        idx = tf.reshape(inputs,[-1])\n",
    "        return tf.gather(self.w, indices=idx, axis=0)\n",
    "    \n",
    "class Dot():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.build()\n",
    "        \n",
    "    def build(self):\n",
    "        self.weights = []\n",
    "        \n",
    "    def __call__(self, inputs):\n",
    "        self.a1 = inputs[0]\n",
    "        self.a2 = inputs[1]\n",
    "        return tf.reduce_sum(self.a1*self.a2, axis=1, keepdims=True)\n",
    "        \n",
    "class LossFunction():\n",
    "        \n",
    "    def __init__(self, model, alpha):\n",
    "        self.model = model\n",
    "        self.alpha = alpha\n",
    "            \n",
    "    def __call__(self, y_true, y_pred):\n",
    "        loss = tf.reduce_mean(tf.square(y_true-y_pred))\n",
    "        regularization1 = tf.reduce_sum(tf.square(self.model.weights[0]))\n",
    "        regularization2 = tf.reduce_sum(tf.square(self.model.weights[1]))\n",
    "        return loss + self.alpha*regularization1 + self.alpha*regularization2 \n",
    "    \n",
    "class Optimizer():\n",
    "\n",
    "    def __init__(self, model, learning_rate, beta_1, beta_2, epsilon):\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.epsilon= epsilon\n",
    "        self.stop_training = False\n",
    "        self.build()\n",
    "        \n",
    "    def add_weight(self, shape):\n",
    "        w_init = tf.zeros(shape=shape, dtype=\"float32\")\n",
    "        return  tf.Variable(initial_value=w_init, trainable=False)\n",
    "    \n",
    "    def build(self):\n",
    "        self.weights = []\n",
    "        for weight in self.model.weights:\n",
    "            m = self.add_weight(shape=weight.shape)\n",
    "            v = self.add_weight(shape=weight.shape)\n",
    "            self.weights.append([m,v])\n",
    "            \n",
    "    def apply(self, grads, weights):\n",
    "        for i in range(len(weights)):\n",
    "            w = weights[i]\n",
    "            grad_w = grads[i]\n",
    "            m = self.weights[i][0]\n",
    "            v = self.weights[i][1]\n",
    "            self.weights[i][0].assign(self.beta_1*m + (1-self.beta_1)*grad_w)  \n",
    "            self.weights[i][1].assign(self.beta_2*v + (1-self.beta_2)*grad_w*grad_w)\n",
    "            m_ = (1/(1-self.beta_1))*self.weights[i][0]\n",
    "            v_ = (1/(1-self.beta_2))*self.weights[i][1]\n",
    "            weights[i].assign(w - self.learning_rate*m_/(tf.math.sqrt(v_)+self.epsilon))\n",
    "            \n",
    "    def train_step(self, X, Y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            H = self.model(X)\n",
    "            loss = self.model.loss(Y, H)\n",
    "        grads = tape.gradient(loss, self.model.weights)\n",
    "        self.apply(grads, self.model.weights)\n",
    "        H = self.model(X)\n",
    "        loss = self.model.loss(Y, H)\n",
    "        logs = {'loss': loss}\n",
    "        return logs  \n",
    "    \n",
    "class Callback1():\n",
    "\n",
    "    def __init__(self, model, verbose):\n",
    "        self.model = model\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.start_time = tf.timestamp()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.verbose:\n",
    "            now = tf.timestamp()\n",
    "            time = now - self.start_time\n",
    "            tf.print('Epochs {}/{} - Loss: {}'.format(epoch+1, self.model.epochs, logs['loss']))\n",
    "            tf.print('--- {}s ---'.format(tf.round(1000*time)/1000))\n",
    "\n",
    "class Callback2():\n",
    "        \n",
    "    def __init__(self, model, patience, error, reduce_factor, min_learning_rate):\n",
    "        self.model = model\n",
    "        self.patience = patience\n",
    "        self.error = error\n",
    "        self.reduce_factor = reduce_factor\n",
    "        self.min_learning_rate = min_learning_rate\n",
    "                        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch==0:\n",
    "            self.loss = logs['loss']\n",
    "            self.non_decreasing_epochs = 0\n",
    "        else:\n",
    "            if ((self.loss-logs['loss'])>self.error):\n",
    "                self.loss = logs['loss']\n",
    "                self.non_decreasing_epochs = 0\n",
    "            else:\n",
    "                self.non_decreasing_epochs = self.non_decreasing_epochs+1\n",
    "        if (self.non_decreasing_epochs == self.patience):\n",
    "            if (self.model.optimizer.learning_rate>self.min_learning_rate):\n",
    "                self.model.optimizer.learning_rate = self.reduce_factor*self.model.optimizer.learning_rate\n",
    "                self.non_decreasing_epochs = 0\n",
    "        \n",
    "class Callback3():\n",
    "        \n",
    "    def __init__(self, model, patience, error):\n",
    "        self.model = model\n",
    "        self.patience = patience\n",
    "        self.error = error\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch==0:\n",
    "            self.loss = logs['loss']\n",
    "            self.non_decreasing_epochs = 0\n",
    "        else:\n",
    "            if ((self.loss-logs['loss'])>self.error):\n",
    "                self.loss = logs['loss']\n",
    "                self.non_decreasing_epochs = 0\n",
    "            else:\n",
    "                self.non_decreasing_epochs = self.non_decreasing_epochs+1\n",
    "        if (self.non_decreasing_epochs == self.patience):\n",
    "            self.model.optimizer.stop_training = True\n",
    "            \n",
    "            \n",
    "class RecommenderSystem():\n",
    "    \n",
    "    def __init__(self, users_dim, content_dim, rank):\n",
    "        self.users_dim = users_dim\n",
    "        self.content_dim = content_dim\n",
    "        self.rank = rank\n",
    "        self.build()\n",
    "     \n",
    "    def build(self):\n",
    "        self.h1 = Embedding(input_dim=self.users_dim, rank=self.rank)\n",
    "        self.h2 = Embedding(input_dim=self.content_dim, rank=self.rank)\n",
    "        self.h3 = Dot()\n",
    "        self.layers = [self.h1, self.h2, self.h3]\n",
    "        self.weights = []\n",
    "        for layer in self.layers:\n",
    "            for weight in layer.weights:\n",
    "                self.weights.append(weight)\n",
    "        \n",
    "    def __call__(self, inputs):\n",
    "        x0 = inputs[0]\n",
    "        x1 = self.h1(x0)\n",
    "        z0 = inputs[1]\n",
    "        z1 = self.h2(z0)\n",
    "        y = self.h3([x1,z1]) \n",
    "        return y \n",
    "        \n",
    "    def train_setup(self, epochs, learning_rate, alpha, beta_1, beta_2, epsilon, verbose):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.alpha = alpha\n",
    "        self.beta_1 = beta_1 \n",
    "        self.beta_2 = beta_2 \n",
    "        self.epsilon = epsilon\n",
    "        self.verbose = verbose\n",
    "        self.loss = LossFunction(model=self, alpha=self.alpha)\n",
    "        self.optimizer = Optimizer(model=self, learning_rate=self.learning_rate, beta_1=self.beta_1, beta_2=self.beta_2, epsilon=self.epsilon) \n",
    "        self.callbacks = [Callback1(model=self, verbose=self.verbose),\n",
    "                          Callback2(model=self, patience=100, error=0.0001, reduce_factor=0.1, min_learning_rate=0.001),\n",
    "                          Callback3(model=self, patience=200, error=0.0001)]\n",
    "        \n",
    "    def fit(self, X, Y, epochs=1000, learning_rate=0.01, alpha=1.0, beta_1=0.9, beta_2=0.999, epsilon=1e-07, verbose=True):\n",
    "        self.train_setup(epochs, learning_rate, alpha, beta_1, beta_2, epsilon,verbose)\n",
    "        if verbose:\n",
    "            tf.print('Train on {} samples'.format(X.shape[0]))\n",
    "        for epoch in range(epochs):\n",
    "            self.callbacks[0].on_epoch_begin(epoch)\n",
    "            logs = self.optimizer.train_step([tf.constant(X[:,[0]], dtype=\"int32\"), tf.constant(X[:,[1]], dtype=\"int32\")], tf.constant(Y, dtype=\"float32\"))\n",
    "            for callback in self.callbacks:\n",
    "                callback.on_epoch_end(epoch, logs)\n",
    "            if self.optimizer.stop_training:\n",
    "                break\n",
    "        self.ratings = tf.matmul(self.weights[0],tf.transpose(self.weights[1]))\n",
    "            \n",
    "    def predict(self, inputs):\n",
    "        return self(inputs).numpy()\n",
    "        \n",
    "    def evaluate(self, X, Y):\n",
    "        loss = self.loss(tf.constant(Y, dtype=\"float32\"), self(X))\n",
    "        return [loss.numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 971368 samples\n",
      "Epochs 1/1000 - Loss: 0.4430158734321594\n",
      "--- 0.981s ---\n",
      "Epochs 2/1000 - Loss: 0.4367488920688629\n",
      "--- 0.477s ---\n",
      "Epochs 3/1000 - Loss: 0.42698410153388977\n",
      "--- 0.45s ---\n",
      "Epochs 4/1000 - Loss: 0.4124116897583008\n",
      "--- 0.454s ---\n",
      "Epochs 5/1000 - Loss: 0.3919110596179962\n",
      "--- 0.459s ---\n",
      "Epochs 6/1000 - Loss: 0.36474254727363586\n",
      "--- 0.452s ---\n",
      "Epochs 7/1000 - Loss: 0.33072277903556824\n",
      "--- 0.475s ---\n",
      "Epochs 8/1000 - Loss: 0.29043862223625183\n",
      "--- 0.456s ---\n",
      "Epochs 9/1000 - Loss: 0.24550069868564606\n",
      "--- 0.47s ---\n",
      "Epochs 10/1000 - Loss: 0.1988012045621872\n",
      "--- 0.481s ---\n",
      "Epochs 11/1000 - Loss: 0.15466147661209106\n",
      "--- 0.457s ---\n",
      "Epochs 12/1000 - Loss: 0.11854439973831177\n",
      "--- 0.482s ---\n",
      "Epochs 13/1000 - Loss: 0.09559983760118484\n",
      "--- 0.452s ---\n",
      "Epochs 14/1000 - Loss: 0.08753407746553421\n",
      "--- 0.457s ---\n",
      "Epochs 15/1000 - Loss: 0.08994290232658386\n",
      "--- 0.459s ---\n",
      "Epochs 16/1000 - Loss: 0.09429771453142166\n",
      "--- 0.448s ---\n",
      "Epochs 17/1000 - Loss: 0.09372907131910324\n",
      "--- 0.452s ---\n",
      "Epochs 18/1000 - Loss: 0.08651423454284668\n",
      "--- 0.454s ---\n",
      "Epochs 19/1000 - Loss: 0.07503575831651688\n",
      "--- 0.453s ---\n",
      "Epochs 20/1000 - Loss: 0.06296198070049286\n",
      "--- 0.462s ---\n",
      "Epochs 21/1000 - Loss: 0.05313309654593468\n",
      "--- 0.452s ---\n",
      "Epochs 22/1000 - Loss: 0.04677344858646393\n",
      "--- 0.447s ---\n",
      "Epochs 23/1000 - Loss: 0.043685100972652435\n",
      "--- 0.443s ---\n",
      "Epochs 24/1000 - Loss: 0.04285816848278046\n",
      "--- 0.444s ---\n",
      "Epochs 25/1000 - Loss: 0.04306914657354355\n",
      "--- 0.453s ---\n",
      "Epochs 26/1000 - Loss: 0.04327581450343132\n",
      "--- 0.455s ---\n",
      "Epochs 27/1000 - Loss: 0.04279707744717598\n",
      "--- 0.452s ---\n",
      "Epochs 28/1000 - Loss: 0.04134199768304825\n",
      "--- 0.447s ---\n",
      "Epochs 29/1000 - Loss: 0.038956400007009506\n",
      "--- 0.449s ---\n",
      "Epochs 30/1000 - Loss: 0.03593077138066292\n",
      "--- 0.442s ---\n",
      "Epochs 31/1000 - Loss: 0.032690055668354034\n",
      "--- 0.444s ---\n",
      "Epochs 32/1000 - Loss: 0.02967500314116478\n",
      "--- 0.449s ---\n",
      "Epochs 33/1000 - Loss: 0.02722836844623089\n",
      "--- 0.451s ---\n",
      "Epochs 34/1000 - Loss: 0.025509878993034363\n",
      "--- 0.454s ---\n",
      "Epochs 35/1000 - Loss: 0.024469099938869476\n",
      "--- 0.446s ---\n",
      "Epochs 36/1000 - Loss: 0.02389070950448513\n",
      "--- 0.449s ---\n",
      "Epochs 37/1000 - Loss: 0.023494290187954903\n",
      "--- 0.447s ---\n",
      "Epochs 38/1000 - Loss: 0.02304248698055744\n",
      "--- 0.45s ---\n",
      "Epochs 39/1000 - Loss: 0.022410599514842033\n",
      "--- 0.448s ---\n",
      "Epochs 40/1000 - Loss: 0.02159656025469303\n",
      "--- 0.453s ---\n",
      "Epochs 41/1000 - Loss: 0.020682334899902344\n",
      "--- 0.455s ---\n",
      "Epochs 42/1000 - Loss: 0.0197762344032526\n",
      "--- 0.444s ---\n",
      "Epochs 43/1000 - Loss: 0.018964575603604317\n",
      "--- 0.449s ---\n",
      "Epochs 44/1000 - Loss: 0.018287908285856247\n",
      "--- 0.45s ---\n",
      "Epochs 45/1000 - Loss: 0.017741667106747627\n",
      "--- 0.453s ---\n",
      "Epochs 46/1000 - Loss: 0.01729200780391693\n",
      "--- 0.455s ---\n",
      "Epochs 47/1000 - Loss: 0.016895858570933342\n",
      "--- 0.45s ---\n",
      "Epochs 48/1000 - Loss: 0.0165171530097723\n",
      "--- 0.467s ---\n",
      "Epochs 49/1000 - Loss: 0.01613549329340458\n",
      "--- 0.443s ---\n",
      "Epochs 50/1000 - Loss: 0.015747064724564552\n",
      "--- 0.451s ---\n",
      "Epochs 51/1000 - Loss: 0.015359810553491116\n",
      "--- 0.452s ---\n",
      "Epochs 52/1000 - Loss: 0.014986035414040089\n",
      "--- 0.447s ---\n",
      "Epochs 53/1000 - Loss: 0.014635737054049969\n",
      "--- 0.453s ---\n",
      "Epochs 54/1000 - Loss: 0.014312895014882088\n",
      "--- 0.443s ---\n",
      "Epochs 55/1000 - Loss: 0.014015517197549343\n",
      "--- 0.446s ---\n",
      "Epochs 56/1000 - Loss: 0.013738345354795456\n",
      "--- 0.456s ---\n",
      "Epochs 57/1000 - Loss: 0.013476255349814892\n",
      "--- 0.45s ---\n",
      "Epochs 58/1000 - Loss: 0.013226483017206192\n",
      "--- 0.439s ---\n",
      "Epochs 59/1000 - Loss: 0.012988893315196037\n",
      "--- 0.45s ---\n",
      "Epochs 60/1000 - Loss: 0.012764686718583107\n",
      "--- 0.449s ---\n",
      "Epochs 61/1000 - Loss: 0.012554608285427094\n",
      "--- 0.445s ---\n",
      "Epochs 62/1000 - Loss: 0.012357753701508045\n",
      "--- 0.46s ---\n",
      "Epochs 63/1000 - Loss: 0.012171509675681591\n",
      "--- 0.446s ---\n",
      "Epochs 64/1000 - Loss: 0.011992428451776505\n",
      "--- 0.45s ---\n",
      "Epochs 65/1000 - Loss: 0.011817526072263718\n",
      "--- 0.455s ---\n",
      "Epochs 66/1000 - Loss: 0.011645285412669182\n",
      "--- 0.454s ---\n",
      "Epochs 67/1000 - Loss: 0.011475981213152409\n",
      "--- 0.456s ---\n",
      "Epochs 68/1000 - Loss: 0.01131129264831543\n",
      "--- 0.453s ---\n",
      "Epochs 69/1000 - Loss: 0.01115337572991848\n",
      "--- 0.449s ---\n",
      "Epochs 70/1000 - Loss: 0.011003897525370121\n",
      "--- 0.448s ---\n",
      "Epochs 71/1000 - Loss: 0.010863345116376877\n",
      "--- 0.453s ---\n",
      "Epochs 72/1000 - Loss: 0.01073086354881525\n",
      "--- 0.446s ---\n",
      "Epochs 73/1000 - Loss: 0.01060462649911642\n",
      "--- 0.448s ---\n",
      "Epochs 74/1000 - Loss: 0.010482546873390675\n",
      "--- 0.457s ---\n",
      "Epochs 75/1000 - Loss: 0.010362968780100346\n",
      "--- 0.451s ---\n",
      "Epochs 76/1000 - Loss: 0.010245129466056824\n",
      "--- 0.457s ---\n",
      "Epochs 77/1000 - Loss: 0.01012919656932354\n",
      "--- 0.472s ---\n",
      "Epochs 78/1000 - Loss: 0.010015950538218021\n",
      "--- 0.452s ---\n",
      "Epochs 79/1000 - Loss: 0.00990629754960537\n",
      "--- 0.448s ---\n",
      "Epochs 80/1000 - Loss: 0.009800832718610764\n",
      "--- 0.454s ---\n",
      "Epochs 81/1000 - Loss: 0.009699610061943531\n",
      "--- 0.468s ---\n",
      "Epochs 82/1000 - Loss: 0.009602178819477558\n",
      "--- 0.449s ---\n",
      "Epochs 83/1000 - Loss: 0.00950780138373375\n",
      "--- 0.452s ---\n",
      "Epochs 84/1000 - Loss: 0.009415761567652225\n",
      "--- 0.455s ---\n",
      "Epochs 85/1000 - Loss: 0.009325573220849037\n",
      "--- 0.454s ---\n",
      "Epochs 86/1000 - Loss: 0.009237086400389671\n",
      "--- 0.444s ---\n",
      "Epochs 87/1000 - Loss: 0.009150426834821701\n",
      "--- 0.446s ---\n",
      "Epochs 88/1000 - Loss: 0.009065845981240273\n",
      "--- 0.448s ---\n",
      "Epochs 89/1000 - Loss: 0.008983558043837547\n",
      "--- 0.454s ---\n",
      "Epochs 90/1000 - Loss: 0.008903625421226025\n",
      "--- 0.45s ---\n",
      "Epochs 91/1000 - Loss: 0.008825934492051601\n",
      "--- 0.453s ---\n",
      "Epochs 92/1000 - Loss: 0.008750242181122303\n",
      "--- 0.447s ---\n",
      "Epochs 93/1000 - Loss: 0.008676272816956043\n",
      "--- 0.45s ---\n",
      "Epochs 94/1000 - Loss: 0.008603802882134914\n",
      "--- 0.449s ---\n",
      "Epochs 95/1000 - Loss: 0.008532720617949963\n",
      "--- 0.45s ---\n",
      "Epochs 96/1000 - Loss: 0.008463017642498016\n",
      "--- 0.455s ---\n",
      "Epochs 97/1000 - Loss: 0.00839474517852068\n",
      "--- 0.456s ---\n",
      "Epochs 98/1000 - Loss: 0.00832795538008213\n",
      "--- 0.445s ---\n",
      "Epochs 99/1000 - Loss: 0.00826266873627901\n",
      "--- 0.448s ---\n",
      "Epochs 100/1000 - Loss: 0.00819883868098259\n",
      "--- 0.449s ---\n",
      "Epochs 101/1000 - Loss: 0.00813637487590313\n",
      "--- 0.447s ---\n",
      "Epochs 102/1000 - Loss: 0.008075169287621975\n",
      "--- 0.463s ---\n",
      "Epochs 103/1000 - Loss: 0.008015125058591366\n",
      "--- 0.45s ---\n",
      "Epochs 104/1000 - Loss: 0.007956180721521378\n",
      "--- 0.455s ---\n",
      "Epochs 105/1000 - Loss: 0.007898308336734772\n",
      "--- 0.459s ---\n",
      "Epochs 106/1000 - Loss: 0.007841500453650951\n",
      "--- 0.457s ---\n",
      "Epochs 107/1000 - Loss: 0.00778575986623764\n",
      "--- 0.455s ---\n",
      "Epochs 108/1000 - Loss: 0.007731074932962656\n",
      "--- 0.448s ---\n",
      "Epochs 109/1000 - Loss: 0.007677421439439058\n",
      "--- 0.453s ---\n",
      "Epochs 110/1000 - Loss: 0.007624755147844553\n",
      "--- 0.448s ---\n",
      "Epochs 111/1000 - Loss: 0.007573028095066547\n",
      "--- 0.458s ---\n",
      "Epochs 112/1000 - Loss: 0.007522196043282747\n",
      "--- 0.454s ---\n",
      "Epochs 113/1000 - Loss: 0.007472225930541754\n",
      "--- 0.457s ---\n",
      "Epochs 114/1000 - Loss: 0.007423092611134052\n",
      "--- 0.455s ---\n",
      "Epochs 115/1000 - Loss: 0.007374783046543598\n",
      "--- 0.45s ---\n",
      "Epochs 116/1000 - Loss: 0.0073272851295769215\n",
      "--- 0.451s ---\n",
      "Epochs 117/1000 - Loss: 0.007280581630766392\n",
      "--- 0.454s ---\n",
      "Epochs 118/1000 - Loss: 0.007234654389321804\n",
      "--- 0.448s ---\n",
      "Epochs 119/1000 - Loss: 0.007189476862549782\n",
      "--- 0.45s ---\n",
      "Epochs 120/1000 - Loss: 0.00714502576738596\n",
      "--- 0.46s ---\n",
      "Epochs 121/1000 - Loss: 0.007101275026798248\n",
      "--- 0.449s ---\n",
      "Epochs 122/1000 - Loss: 0.0070582060143351555\n",
      "--- 0.449s ---\n",
      "Epochs 123/1000 - Loss: 0.007015802897512913\n",
      "--- 0.452s ---\n",
      "Epochs 124/1000 - Loss: 0.006974048912525177\n",
      "--- 0.452s ---\n",
      "Epochs 125/1000 - Loss: 0.006932934280484915\n",
      "--- 0.45s ---\n",
      "Epochs 126/1000 - Loss: 0.00689244270324707\n",
      "--- 0.457s ---\n",
      "Epochs 127/1000 - Loss: 0.0068525588139891624\n",
      "--- 0.454s ---\n",
      "Epochs 128/1000 - Loss: 0.00681326724588871\n",
      "--- 0.454s ---\n",
      "Epochs 129/1000 - Loss: 0.006774549838155508\n",
      "--- 0.455s ---\n",
      "Epochs 130/1000 - Loss: 0.006736392620950937\n",
      "--- 0.452s ---\n",
      "Epochs 131/1000 - Loss: 0.0066987816244363785\n",
      "--- 0.453s ---\n",
      "Epochs 132/1000 - Loss: 0.006661705207079649\n",
      "--- 0.463s ---\n",
      "Epochs 133/1000 - Loss: 0.006625152193009853\n",
      "--- 0.448s ---\n",
      "Epochs 134/1000 - Loss: 0.006589112803339958\n",
      "--- 0.451s ---\n",
      "Epochs 135/1000 - Loss: 0.0065535735338926315\n",
      "--- 0.448s ---\n",
      "Epochs 136/1000 - Loss: 0.006518524140119553\n",
      "--- 0.45s ---\n",
      "Epochs 137/1000 - Loss: 0.006483954377472401\n",
      "--- 0.449s ---\n",
      "Epochs 138/1000 - Loss: 0.006449849810451269\n",
      "--- 0.445s ---\n",
      "Epochs 139/1000 - Loss: 0.006416200194507837\n",
      "--- 0.451s ---\n",
      "Epochs 140/1000 - Loss: 0.006382998079061508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.451s ---\n",
      "Epochs 141/1000 - Loss: 0.006350231822580099\n",
      "--- 0.451s ---\n",
      "Epochs 142/1000 - Loss: 0.006317893508821726\n",
      "--- 0.454s ---\n",
      "Epochs 143/1000 - Loss: 0.006285973358899355\n",
      "--- 0.454s ---\n",
      "Epochs 144/1000 - Loss: 0.006254463456571102\n",
      "--- 0.444s ---\n",
      "Epochs 145/1000 - Loss: 0.006223355885595083\n",
      "--- 0.438s ---\n",
      "Epochs 146/1000 - Loss: 0.006192641798406839\n",
      "--- 0.437s ---\n",
      "Epochs 147/1000 - Loss: 0.006162311881780624\n",
      "--- 0.451s ---\n",
      "Epochs 148/1000 - Loss: 0.006132359150797129\n",
      "--- 0.452s ---\n",
      "Epochs 149/1000 - Loss: 0.006102775223553181\n",
      "--- 0.453s ---\n",
      "Epochs 150/1000 - Loss: 0.006073553115129471\n",
      "--- 0.444s ---\n",
      "Epochs 151/1000 - Loss: 0.006044686771929264\n",
      "--- 0.459s ---\n",
      "Epochs 152/1000 - Loss: 0.006016166880726814\n",
      "--- 0.451s ---\n",
      "Epochs 153/1000 - Loss: 0.005987989250570536\n",
      "--- 0.448s ---\n",
      "Epochs 154/1000 - Loss: 0.005960145499557257\n",
      "--- 0.45s ---\n",
      "Epochs 155/1000 - Loss: 0.00593263003975153\n",
      "--- 0.45s ---\n",
      "Epochs 156/1000 - Loss: 0.005905435886234045\n",
      "--- 0.448s ---\n",
      "Epochs 157/1000 - Loss: 0.005878557451069355\n",
      "--- 0.447s ---\n",
      "Epochs 158/1000 - Loss: 0.005851988214999437\n",
      "--- 0.447s ---\n",
      "Epochs 159/1000 - Loss: 0.005825723055750132\n",
      "--- 0.452s ---\n",
      "Epochs 160/1000 - Loss: 0.00579975638538599\n",
      "--- 0.462s ---\n",
      "Epochs 161/1000 - Loss: 0.005774082150310278\n",
      "--- 0.45s ---\n",
      "Epochs 162/1000 - Loss: 0.005748695228248835\n",
      "--- 0.45s ---\n",
      "Epochs 163/1000 - Loss: 0.0057235900312662125\n",
      "--- 0.454s ---\n",
      "Epochs 164/1000 - Loss: 0.0056987632997334\n",
      "--- 0.442s ---\n",
      "Epochs 165/1000 - Loss: 0.005674207117408514\n",
      "--- 0.443s ---\n",
      "Epochs 166/1000 - Loss: 0.005649917759001255\n",
      "--- 0.448s ---\n",
      "Epochs 167/1000 - Loss: 0.005625891964882612\n",
      "--- 0.445s ---\n",
      "Epochs 168/1000 - Loss: 0.005602124147117138\n",
      "--- 0.447s ---\n",
      "Epochs 169/1000 - Loss: 0.005578609183430672\n",
      "--- 0.457s ---\n",
      "Epochs 170/1000 - Loss: 0.005555343814194202\n",
      "--- 0.451s ---\n",
      "Epochs 171/1000 - Loss: 0.005532323382794857\n",
      "--- 0.439s ---\n",
      "Epochs 172/1000 - Loss: 0.005509542766958475\n",
      "--- 0.452s ---\n",
      "Epochs 173/1000 - Loss: 0.0054869987070560455\n",
      "--- 0.45s ---\n",
      "Epochs 174/1000 - Loss: 0.00546468747779727\n",
      "--- 0.448s ---\n",
      "Epochs 175/1000 - Loss: 0.0054426053538918495\n",
      "--- 0.448s ---\n",
      "Epochs 176/1000 - Loss: 0.005420747213065624\n",
      "--- 0.449s ---\n",
      "Epochs 177/1000 - Loss: 0.0053991107270121574\n",
      "--- 0.454s ---\n",
      "Epochs 178/1000 - Loss: 0.005377691704779863\n",
      "--- 0.454s ---\n",
      "Epochs 179/1000 - Loss: 0.0053564864210784435\n",
      "--- 0.454s ---\n",
      "Epochs 180/1000 - Loss: 0.005335492081940174\n",
      "--- 0.453s ---\n",
      "Epochs 181/1000 - Loss: 0.005314704962074757\n",
      "--- 0.45s ---\n",
      "Epochs 182/1000 - Loss: 0.005294121336191893\n",
      "--- 0.449s ---\n",
      "Epochs 183/1000 - Loss: 0.005273738410323858\n",
      "--- 0.444s ---\n",
      "Epochs 184/1000 - Loss: 0.005253552924841642\n",
      "--- 0.447s ---\n",
      "Epochs 185/1000 - Loss: 0.0052335611544549465\n",
      "--- 0.446s ---\n",
      "Epochs 186/1000 - Loss: 0.005213761702179909\n",
      "--- 0.444s ---\n",
      "Epochs 187/1000 - Loss: 0.005194149911403656\n",
      "--- 0.453s ---\n",
      "Epochs 188/1000 - Loss: 0.005174724385142326\n",
      "--- 0.464s ---\n",
      "Epochs 189/1000 - Loss: 0.005155480932444334\n",
      "--- 0.448s ---\n",
      "Epochs 190/1000 - Loss: 0.00513641769066453\n",
      "--- 0.446s ---\n",
      "Epochs 191/1000 - Loss: 0.005117530468851328\n",
      "--- 0.445s ---\n",
      "Epochs 192/1000 - Loss: 0.005098818801343441\n",
      "--- 0.446s ---\n",
      "Epochs 193/1000 - Loss: 0.005080278497189283\n",
      "--- 0.453s ---\n",
      "Epochs 194/1000 - Loss: 0.0050619072280824184\n",
      "--- 0.444s ---\n",
      "Epochs 195/1000 - Loss: 0.005043703131377697\n",
      "--- 0.448s ---\n",
      "Epochs 196/1000 - Loss: 0.00502566434442997\n",
      "--- 0.449s ---\n",
      "Epochs 197/1000 - Loss: 0.005007786676287651\n",
      "--- 0.45s ---\n",
      "Epochs 198/1000 - Loss: 0.004990068729966879\n",
      "--- 0.451s ---\n",
      "Epochs 199/1000 - Loss: 0.004972508177161217\n",
      "--- 0.453s ---\n",
      "Epochs 200/1000 - Loss: 0.004955102223902941\n",
      "--- 0.452s ---\n",
      "Epochs 201/1000 - Loss: 0.004937849938869476\n",
      "--- 0.449s ---\n",
      "Epochs 202/1000 - Loss: 0.004920747596770525\n",
      "--- 0.453s ---\n",
      "Epochs 203/1000 - Loss: 0.004903794731944799\n",
      "--- 0.446s ---\n",
      "Epochs 204/1000 - Loss: 0.004886987619102001\n",
      "--- 0.451s ---\n",
      "Epochs 205/1000 - Loss: 0.004870325792580843\n",
      "--- 0.45s ---\n",
      "Epochs 206/1000 - Loss: 0.004853805527091026\n",
      "--- 0.451s ---\n",
      "Epochs 207/1000 - Loss: 0.004837425891309977\n",
      "--- 0.446s ---\n",
      "Epochs 208/1000 - Loss: 0.0048211850225925446\n",
      "--- 0.452s ---\n",
      "Epochs 209/1000 - Loss: 0.004805081058293581\n",
      "--- 0.458s ---\n",
      "Epochs 210/1000 - Loss: 0.004789112135767937\n",
      "--- 0.452s ---\n",
      "Epochs 211/1000 - Loss: 0.004773275926709175\n",
      "--- 0.448s ---\n",
      "Epochs 212/1000 - Loss: 0.00475757010281086\n",
      "--- 0.443s ---\n",
      "Epochs 213/1000 - Loss: 0.004741995129734278\n",
      "--- 0.458s ---\n",
      "Epochs 214/1000 - Loss: 0.004726547747850418\n",
      "--- 0.452s ---\n",
      "Epochs 215/1000 - Loss: 0.004711225628852844\n",
      "--- 0.456s ---\n",
      "Epochs 216/1000 - Loss: 0.004696028772741556\n",
      "--- 0.443s ---\n",
      "Epochs 217/1000 - Loss: 0.004680954851210117\n",
      "--- 0.459s ---\n",
      "Epochs 218/1000 - Loss: 0.004666001070290804\n",
      "--- 0.451s ---\n",
      "Epochs 219/1000 - Loss: 0.0046511683613061905\n",
      "--- 0.445s ---\n",
      "Epochs 220/1000 - Loss: 0.004636452998965979\n",
      "--- 0.445s ---\n",
      "Epochs 221/1000 - Loss: 0.004621854517608881\n",
      "--- 0.45s ---\n",
      "Epochs 222/1000 - Loss: 0.004607371054589748\n",
      "--- 0.448s ---\n",
      "Epochs 223/1000 - Loss: 0.0045930007472634315\n",
      "--- 0.456s ---\n",
      "Epochs 224/1000 - Loss: 0.004578744061291218\n",
      "--- 0.451s ---\n",
      "Epochs 225/1000 - Loss: 0.004564596805721521\n",
      "--- 0.454s ---\n",
      "Epochs 226/1000 - Loss: 0.0045505608431994915\n",
      "--- 0.45s ---\n",
      "Epochs 227/1000 - Loss: 0.004536631517112255\n",
      "--- 0.449s ---\n",
      "Epochs 228/1000 - Loss: 0.004522809758782387\n",
      "--- 0.452s ---\n",
      "Epochs 229/1000 - Loss: 0.004509092774242163\n",
      "--- 0.45s ---\n",
      "Epochs 230/1000 - Loss: 0.0044954800978302956\n",
      "--- 0.455s ---\n",
      "Epochs 231/1000 - Loss: 0.004481971263885498\n",
      "--- 0.449s ---\n",
      "Epochs 232/1000 - Loss: 0.004468563012778759\n",
      "--- 0.452s ---\n",
      "Epochs 233/1000 - Loss: 0.004455255810171366\n",
      "--- 0.449s ---\n",
      "Epochs 234/1000 - Loss: 0.004442047327756882\n",
      "--- 0.445s ---\n",
      "Epochs 235/1000 - Loss: 0.0044289384968578815\n",
      "--- 0.449s ---\n",
      "Epochs 236/1000 - Loss: 0.0044159251265227795\n",
      "--- 0.454s ---\n",
      "Epochs 237/1000 - Loss: 0.004403007682412863\n",
      "--- 0.453s ---\n",
      "Epochs 238/1000 - Loss: 0.004390185698866844\n",
      "--- 0.448s ---\n",
      "Epochs 239/1000 - Loss: 0.004377456381917\n",
      "--- 0.451s ---\n",
      "Epochs 240/1000 - Loss: 0.004364820197224617\n",
      "--- 0.452s ---\n",
      "Epochs 241/1000 - Loss: 0.0043522752821445465\n",
      "--- 0.441s ---\n",
      "Epochs 242/1000 - Loss: 0.004339820705354214\n",
      "--- 0.464s ---\n",
      "Epochs 243/1000 - Loss: 0.004327455535531044\n",
      "--- 0.45s ---\n",
      "Epochs 244/1000 - Loss: 0.004315178841352463\n",
      "--- 0.45s ---\n",
      "Epochs 245/1000 - Loss: 0.004302988760173321\n",
      "--- 0.455s ---\n",
      "Epochs 246/1000 - Loss: 0.004290885291993618\n",
      "--- 0.454s ---\n",
      "Epochs 247/1000 - Loss: 0.00427886750549078\n",
      "--- 0.453s ---\n",
      "Epochs 248/1000 - Loss: 0.004266933538019657\n",
      "--- 0.445s ---\n",
      "Epochs 249/1000 - Loss: 0.00425508338958025\n",
      "--- 0.449s ---\n",
      "Epochs 250/1000 - Loss: 0.004243316128849983\n",
      "--- 0.469s ---\n",
      "Epochs 251/1000 - Loss: 0.004231629893183708\n",
      "--- 0.452s ---\n",
      "Epochs 252/1000 - Loss: 0.004220024682581425\n",
      "--- 0.453s ---\n",
      "Epochs 253/1000 - Loss: 0.0042084986343979836\n",
      "--- 0.452s ---\n",
      "Epochs 254/1000 - Loss: 0.004197052214294672\n",
      "--- 0.47s ---\n",
      "Epochs 255/1000 - Loss: 0.004185684025287628\n",
      "--- 0.448s ---\n",
      "Epochs 256/1000 - Loss: 0.00417439267039299\n",
      "--- 0.45s ---\n",
      "Epochs 257/1000 - Loss: 0.0041631776839494705\n",
      "--- 0.452s ---\n",
      "Epochs 258/1000 - Loss: 0.004152038600295782\n",
      "--- 0.452s ---\n",
      "Epochs 259/1000 - Loss: 0.004140974022448063\n",
      "--- 0.45s ---\n",
      "Epochs 260/1000 - Loss: 0.004129983950406313\n",
      "--- 0.452s ---\n",
      "Epochs 261/1000 - Loss: 0.00411906698718667\n",
      "--- 0.455s ---\n",
      "Epochs 262/1000 - Loss: 0.00410822220146656\n",
      "--- 0.452s ---\n",
      "Epochs 263/1000 - Loss: 0.004097449127584696\n",
      "--- 0.444s ---\n",
      "Epochs 264/1000 - Loss: 0.004086747299879789\n",
      "--- 0.452s ---\n",
      "Epochs 265/1000 - Loss: 0.004076114855706692\n",
      "--- 0.451s ---\n",
      "Epochs 266/1000 - Loss: 0.00406555226072669\n",
      "--- 0.447s ---\n",
      "Epochs 267/1000 - Loss: 0.00405505858361721\n",
      "--- 0.454s ---\n",
      "Epochs 268/1000 - Loss: 0.004044633358716965\n",
      "--- 0.445s ---\n",
      "Epochs 269/1000 - Loss: 0.004034274257719517\n",
      "--- 0.438s ---\n",
      "Epochs 270/1000 - Loss: 0.004023983143270016\n",
      "--- 0.435s ---\n",
      "Epochs 271/1000 - Loss: 0.004013757221400738\n",
      "--- 0.46s ---\n",
      "Epochs 272/1000 - Loss: 0.00400359695777297\n",
      "--- 0.441s ---\n",
      "Epochs 273/1000 - Loss: 0.003993500955402851\n",
      "--- 0.447s ---\n",
      "Epochs 274/1000 - Loss: 0.0039834692142903805\n",
      "--- 0.454s ---\n",
      "Epochs 275/1000 - Loss: 0.003973500803112984\n",
      "--- 0.446s ---\n",
      "Epochs 276/1000 - Loss: 0.0039635952562093735\n",
      "--- 0.447s ---\n",
      "Epochs 277/1000 - Loss: 0.003953751642256975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.448s ---\n",
      "Epochs 278/1000 - Loss: 0.003943969029933214\n",
      "--- 0.449s ---\n",
      "Epochs 279/1000 - Loss: 0.003934247884899378\n",
      "--- 0.459s ---\n",
      "Epochs 280/1000 - Loss: 0.003924586810171604\n",
      "--- 0.448s ---\n",
      "Epochs 281/1000 - Loss: 0.003914985340088606\n",
      "--- 0.45s ---\n",
      "Epochs 282/1000 - Loss: 0.0039054432418197393\n",
      "--- 0.456s ---\n",
      "Epochs 283/1000 - Loss: 0.0038959598168730736\n",
      "--- 0.446s ---\n",
      "Epochs 284/1000 - Loss: 0.0038865336682647467\n",
      "--- 0.441s ---\n",
      "Epochs 285/1000 - Loss: 0.0038771650288254023\n",
      "--- 0.448s ---\n",
      "Epochs 286/1000 - Loss: 0.0038678532000631094\n",
      "--- 0.446s ---\n",
      "Epochs 287/1000 - Loss: 0.0038585979491472244\n",
      "--- 0.456s ---\n",
      "Epochs 288/1000 - Loss: 0.0038493985775858164\n",
      "--- 0.447s ---\n",
      "Epochs 289/1000 - Loss: 0.0038402541540563107\n",
      "--- 0.447s ---\n",
      "Epochs 290/1000 - Loss: 0.003831164911389351\n",
      "--- 0.449s ---\n",
      "Epochs 291/1000 - Loss: 0.003822128754109144\n",
      "--- 0.45s ---\n",
      "Epochs 292/1000 - Loss: 0.003813147312030196\n",
      "--- 0.446s ---\n",
      "Epochs 293/1000 - Loss: 0.0038042187225073576\n",
      "--- 0.449s ---\n",
      "Epochs 294/1000 - Loss: 0.0037953429855406284\n",
      "--- 0.451s ---\n",
      "Epochs 295/1000 - Loss: 0.003786519169807434\n",
      "--- 0.444s ---\n",
      "Epochs 296/1000 - Loss: 0.003777747042477131\n",
      "--- 0.451s ---\n",
      "Epochs 297/1000 - Loss: 0.0037690261378884315\n",
      "--- 0.449s ---\n",
      "Epochs 298/1000 - Loss: 0.0037603559903800488\n",
      "--- 0.443s ---\n",
      "Epochs 299/1000 - Loss: 0.003751736134290695\n",
      "--- 0.468s ---\n",
      "Epochs 300/1000 - Loss: 0.00374316587112844\n",
      "--- 0.451s ---\n",
      "Epochs 301/1000 - Loss: 0.0037346447352319956\n",
      "--- 0.456s ---\n",
      "Epochs 302/1000 - Loss: 0.0037261731922626495\n",
      "--- 0.444s ---\n",
      "Epochs 303/1000 - Loss: 0.003717749612405896\n",
      "--- 0.449s ---\n",
      "Epochs 304/1000 - Loss: 0.003709374228492379\n",
      "--- 0.456s ---\n",
      "Epochs 305/1000 - Loss: 0.0037010458763688803\n",
      "--- 0.45s ---\n",
      "Epochs 306/1000 - Loss: 0.003692765487357974\n",
      "--- 0.444s ---\n",
      "Epochs 307/1000 - Loss: 0.0036845316644757986\n",
      "--- 0.447s ---\n",
      "Epochs 308/1000 - Loss: 0.0036763434763997793\n",
      "--- 0.447s ---\n",
      "Epochs 309/1000 - Loss: 0.003668202320113778\n",
      "--- 0.452s ---\n",
      "Epochs 310/1000 - Loss: 0.003660105634480715\n",
      "--- 0.449s ---\n",
      "Epochs 311/1000 - Loss: 0.003652054350823164\n",
      "--- 0.447s ---\n",
      "Epochs 312/1000 - Loss: 0.0036440480034798384\n",
      "--- 0.448s ---\n",
      "Epochs 313/1000 - Loss: 0.0036360856611281633\n",
      "--- 0.443s ---\n",
      "Epochs 314/1000 - Loss: 0.0036281670909374952\n",
      "--- 0.449s ---\n",
      "Epochs 315/1000 - Loss: 0.0036202927585691214\n",
      "--- 0.454s ---\n",
      "Epochs 316/1000 - Loss: 0.003612460568547249\n",
      "--- 0.453s ---\n",
      "Epochs 317/1000 - Loss: 0.0036046714521944523\n",
      "--- 0.521s ---\n",
      "Epochs 318/1000 - Loss: 0.003596925176680088\n",
      "--- 0.443s ---\n",
      "Epochs 319/1000 - Loss: 0.003589220345020294\n",
      "--- 0.46s ---\n",
      "Epochs 320/1000 - Loss: 0.0035815576557070017\n",
      "--- 0.453s ---\n",
      "Epochs 321/1000 - Loss: 0.0035739359445869923\n",
      "--- 0.452s ---\n",
      "Epochs 322/1000 - Loss: 0.003566355211660266\n",
      "--- 0.448s ---\n",
      "Epochs 323/1000 - Loss: 0.003558815224096179\n",
      "--- 0.448s ---\n",
      "Epochs 324/1000 - Loss: 0.0035513152834028006\n",
      "--- 0.453s ---\n",
      "Epochs 325/1000 - Loss: 0.0035438556224107742\n",
      "--- 0.448s ---\n",
      "Epochs 326/1000 - Loss: 0.0035364350769668818\n",
      "--- 0.445s ---\n",
      "Epochs 327/1000 - Loss: 0.0035290541127324104\n",
      "--- 0.463s ---\n",
      "Epochs 328/1000 - Loss: 0.003521711565554142\n",
      "--- 0.451s ---\n",
      "Epochs 329/1000 - Loss: 0.0035144079010933638\n",
      "--- 0.45s ---\n",
      "Epochs 330/1000 - Loss: 0.0035071426536887884\n",
      "--- 0.449s ---\n",
      "Epochs 331/1000 - Loss: 0.0034999148920178413\n",
      "--- 0.452s ---\n",
      "Epochs 332/1000 - Loss: 0.00349272508174181\n",
      "--- 0.449s ---\n",
      "Epochs 333/1000 - Loss: 0.0034855722915381193\n",
      "--- 0.447s ---\n",
      "Epochs 334/1000 - Loss: 0.0034784567542374134\n",
      "--- 0.449s ---\n",
      "Epochs 335/1000 - Loss: 0.003471377771347761\n",
      "--- 0.45s ---\n",
      "Epochs 336/1000 - Loss: 0.0034643353428691626\n",
      "--- 0.447s ---\n",
      "Epochs 337/1000 - Loss: 0.0034573287703096867\n",
      "--- 0.448s ---\n",
      "Epochs 338/1000 - Loss: 0.003450358286499977\n",
      "--- 0.443s ---\n",
      "Epochs 339/1000 - Loss: 0.003443423192948103\n",
      "--- 0.442s ---\n",
      "Epochs 340/1000 - Loss: 0.0034365232568234205\n",
      "--- 0.452s ---\n",
      "Epochs 341/1000 - Loss: 0.003429657779633999\n",
      "--- 0.455s ---\n",
      "Epochs 342/1000 - Loss: 0.0034228276927024126\n",
      "--- 0.444s ---\n",
      "Epochs 343/1000 - Loss: 0.003416031366214156\n",
      "--- 0.451s ---\n",
      "Epochs 344/1000 - Loss: 0.0034092694986611605\n",
      "--- 0.452s ---\n",
      "Epochs 345/1000 - Loss: 0.0034025413915514946\n",
      "--- 0.456s ---\n",
      "Epochs 346/1000 - Loss: 0.003395846812054515\n",
      "--- 0.449s ---\n",
      "Epochs 347/1000 - Loss: 0.003389185294508934\n",
      "--- 0.447s ---\n",
      "Epochs 348/1000 - Loss: 0.003382556838914752\n",
      "--- 0.444s ---\n",
      "Epochs 349/1000 - Loss: 0.003375961212441325\n",
      "--- 0.45s ---\n",
      "Epochs 350/1000 - Loss: 0.00336939818225801\n",
      "--- 0.445s ---\n",
      "Epochs 351/1000 - Loss: 0.003362867748364806\n",
      "--- 0.45s ---\n",
      "Epochs 352/1000 - Loss: 0.0033563680481165648\n",
      "--- 0.456s ---\n",
      "Epochs 353/1000 - Loss: 0.0033499011769890785\n",
      "--- 0.448s ---\n",
      "Epochs 354/1000 - Loss: 0.0033434657379984856\n",
      "--- 0.451s ---\n",
      "Epochs 355/1000 - Loss: 0.0033370607998222113\n",
      "--- 0.467s ---\n",
      "Epochs 356/1000 - Loss: 0.003330687526613474\n",
      "--- 0.444s ---\n",
      "Epochs 357/1000 - Loss: 0.003324344987049699\n",
      "--- 0.453s ---\n",
      "Epochs 358/1000 - Loss: 0.0033180327154695988\n",
      "--- 0.45s ---\n",
      "Epochs 359/1000 - Loss: 0.0033117502462118864\n",
      "--- 0.447s ---\n",
      "Epochs 360/1000 - Loss: 0.0033054985105991364\n",
      "--- 0.437s ---\n",
      "Epochs 361/1000 - Loss: 0.0032992763444781303\n",
      "--- 0.446s ---\n",
      "Epochs 362/1000 - Loss: 0.003293083980679512\n",
      "--- 0.444s ---\n",
      "Epochs 363/1000 - Loss: 0.0032869207207113504\n",
      "--- 0.444s ---\n",
      "Epochs 364/1000 - Loss: 0.003280786331743002\n",
      "--- 0.444s ---\n",
      "Epochs 365/1000 - Loss: 0.0032746815122663975\n",
      "--- 0.454s ---\n",
      "Epochs 366/1000 - Loss: 0.003268604865297675\n",
      "--- 0.443s ---\n",
      "Epochs 367/1000 - Loss: 0.003262557089328766\n",
      "--- 0.449s ---\n",
      "Epochs 368/1000 - Loss: 0.0032565374858677387\n",
      "--- 0.446s ---\n",
      "Epochs 369/1000 - Loss: 0.0032505455892533064\n",
      "--- 0.459s ---\n",
      "Epochs 370/1000 - Loss: 0.0032445816323161125\n",
      "--- 0.46s ---\n",
      "Epochs 371/1000 - Loss: 0.0032386453822255135\n",
      "--- 0.45s ---\n",
      "Epochs 372/1000 - Loss: 0.0032327366061508656\n",
      "--- 0.449s ---\n",
      "Epochs 373/1000 - Loss: 0.003226855071261525\n",
      "--- 0.444s ---\n",
      "Epochs 374/1000 - Loss: 0.0032210005447268486\n",
      "--- 0.445s ---\n",
      "Epochs 375/1000 - Loss: 0.0032151725608855486\n",
      "--- 0.448s ---\n",
      "Epochs 376/1000 - Loss: 0.0032093720510601997\n",
      "--- 0.45s ---\n",
      "Epochs 377/1000 - Loss: 0.003203597152605653\n",
      "--- 0.45s ---\n",
      "Epochs 378/1000 - Loss: 0.0031978487968444824\n",
      "--- 0.447s ---\n",
      "Epochs 379/1000 - Loss: 0.003192126052454114\n",
      "--- 0.457s ---\n",
      "Epochs 380/1000 - Loss: 0.0031864296179264784\n",
      "--- 0.444s ---\n",
      "Epochs 381/1000 - Loss: 0.0031807590276002884\n",
      "--- 0.449s ---\n",
      "Epochs 382/1000 - Loss: 0.0031751133501529694\n",
      "--- 0.465s ---\n",
      "Epochs 383/1000 - Loss: 0.0031694932840764523\n",
      "--- 0.449s ---\n",
      "Epochs 384/1000 - Loss: 0.0031638983637094498\n",
      "--- 0.452s ---\n",
      "Epochs 385/1000 - Loss: 0.0031583281233906746\n",
      "--- 0.45s ---\n",
      "Epochs 386/1000 - Loss: 0.0031527832616120577\n",
      "--- 0.449s ---\n",
      "Epochs 387/1000 - Loss: 0.003147262381389737\n",
      "--- 0.441s ---\n",
      "Epochs 388/1000 - Loss: 0.0031417664140462875\n",
      "--- 0.448s ---\n",
      "Epochs 389/1000 - Loss: 0.0031362941954284906\n",
      "--- 0.45s ---\n",
      "Epochs 390/1000 - Loss: 0.00313084595836699\n",
      "--- 0.45s ---\n",
      "Epochs 391/1000 - Loss: 0.003125421702861786\n",
      "--- 0.46s ---\n",
      "Epochs 392/1000 - Loss: 0.0031200216617435217\n",
      "--- 0.448s ---\n",
      "Epochs 393/1000 - Loss: 0.003114644903689623\n",
      "--- 0.446s ---\n",
      "Epochs 394/1000 - Loss: 0.003109291661530733\n",
      "--- 0.45s ---\n",
      "Epochs 395/1000 - Loss: 0.0031039612367749214\n",
      "--- 0.446s ---\n",
      "Epochs 396/1000 - Loss: 0.003098654095083475\n",
      "--- 0.449s ---\n",
      "Epochs 397/1000 - Loss: 0.0030933700036257505\n",
      "--- 0.452s ---\n",
      "Epochs 398/1000 - Loss: 0.0030881084967404604\n",
      "--- 0.45s ---\n",
      "Epochs 399/1000 - Loss: 0.003082869341596961\n",
      "--- 0.447s ---\n",
      "Epochs 400/1000 - Loss: 0.0030776530038565397\n",
      "--- 0.448s ---\n",
      "Epochs 401/1000 - Loss: 0.003072459250688553\n",
      "--- 0.445s ---\n",
      "Epochs 402/1000 - Loss: 0.003067286917939782\n",
      "--- 0.445s ---\n",
      "Epochs 403/1000 - Loss: 0.0030621367041021585\n",
      "--- 0.448s ---\n",
      "Epochs 404/1000 - Loss: 0.0030570088420063257\n",
      "--- 0.45s ---\n",
      "Epochs 405/1000 - Loss: 0.0030519021674990654\n",
      "--- 0.453s ---\n",
      "Epochs 406/1000 - Loss: 0.003046817146241665\n",
      "--- 0.449s ---\n",
      "Epochs 407/1000 - Loss: 0.003041753778234124\n",
      "--- 0.447s ---\n",
      "Epochs 408/1000 - Loss: 0.0030367111321538687\n",
      "--- 0.444s ---\n",
      "Epochs 409/1000 - Loss: 0.003031690139323473\n",
      "--- 0.459s ---\n",
      "Epochs 410/1000 - Loss: 0.003026689635589719\n",
      "--- 0.46s ---\n",
      "Epochs 411/1000 - Loss: 0.003021710552275181\n",
      "--- 0.46s ---\n",
      "Epochs 412/1000 - Loss: 0.003016751492395997\n",
      "--- 0.454s ---\n",
      "Epochs 413/1000 - Loss: 0.0030118136201053858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.445s ---\n",
      "Epochs 414/1000 - Loss: 0.0030068957712501287\n",
      "--- 0.444s ---\n",
      "Epochs 415/1000 - Loss: 0.003001997945830226\n",
      "--- 0.446s ---\n",
      "Epochs 416/1000 - Loss: 0.0029971206095069647\n",
      "--- 0.451s ---\n",
      "Epochs 417/1000 - Loss: 0.0029922632966190577\n",
      "--- 0.451s ---\n",
      "Epochs 418/1000 - Loss: 0.002987426007166505\n",
      "--- 0.448s ---\n",
      "Epochs 419/1000 - Loss: 0.002982608275488019\n",
      "--- 0.45s ---\n",
      "Epochs 420/1000 - Loss: 0.0029778103344142437\n",
      "--- 0.451s ---\n",
      "Epochs 421/1000 - Loss: 0.0029730317182838917\n",
      "--- 0.45s ---\n",
      "Epochs 422/1000 - Loss: 0.0029682721942663193\n",
      "--- 0.446s ---\n",
      "Epochs 423/1000 - Loss: 0.002963532228022814\n",
      "--- 0.45s ---\n",
      "Epochs 424/1000 - Loss: 0.002958811353892088\n",
      "--- 0.45s ---\n",
      "Epochs 425/1000 - Loss: 0.0029541095718741417\n",
      "--- 0.442s ---\n",
      "Epochs 426/1000 - Loss: 0.0029494266491383314\n",
      "--- 0.446s ---\n",
      "Epochs 427/1000 - Loss: 0.002944762585684657\n",
      "--- 0.455s ---\n",
      "Epochs 428/1000 - Loss: 0.0029401169158518314\n",
      "--- 0.445s ---\n",
      "Epochs 429/1000 - Loss: 0.0029354901053011417\n",
      "--- 0.447s ---\n",
      "Epochs 430/1000 - Loss: 0.002930881455540657\n",
      "--- 0.449s ---\n",
      "Epochs 431/1000 - Loss: 0.0029262909665703773\n",
      "--- 0.453s ---\n",
      "Epochs 432/1000 - Loss: 0.0029217188712209463\n",
      "--- 0.448s ---\n",
      "Epochs 433/1000 - Loss: 0.0029171649366617203\n",
      "--- 0.454s ---\n",
      "Epochs 434/1000 - Loss: 0.002912628697231412\n",
      "--- 0.454s ---\n",
      "Epochs 435/1000 - Loss: 0.0029081101529300213\n",
      "--- 0.444s ---\n",
      "Epochs 436/1000 - Loss: 0.0029036097694188356\n",
      "--- 0.444s ---\n",
      "Epochs 437/1000 - Loss: 0.0028991263825446367\n",
      "--- 0.446s ---\n",
      "Epochs 438/1000 - Loss: 0.002894661156460643\n",
      "--- 0.443s ---\n",
      "Epochs 439/1000 - Loss: 0.0028902129270136356\n",
      "--- 0.462s ---\n",
      "Epochs 440/1000 - Loss: 0.002885782392695546\n",
      "--- 0.449s ---\n",
      "Epochs 441/1000 - Loss: 0.002881368389353156\n",
      "--- 0.447s ---\n",
      "Epochs 442/1000 - Loss: 0.0028769720811396837\n",
      "--- 0.445s ---\n",
      "Epochs 443/1000 - Loss: 0.0028725925367325544\n",
      "--- 0.455s ---\n",
      "Epochs 444/1000 - Loss: 0.002868229988962412\n",
      "--- 0.446s ---\n",
      "Epochs 445/1000 - Loss: 0.0028638839721679688\n",
      "--- 0.446s ---\n",
      "Epochs 446/1000 - Loss: 0.002859554486349225\n",
      "--- 0.449s ---\n",
      "Epochs 447/1000 - Loss: 0.0028552417643368244\n",
      "--- 0.445s ---\n",
      "Epochs 448/1000 - Loss: 0.002850945573300123\n",
      "--- 0.448s ---\n",
      "Epochs 449/1000 - Loss: 0.002846665680408478\n",
      "--- 0.442s ---\n",
      "Epochs 450/1000 - Loss: 0.0028424023184925318\n",
      "--- 0.443s ---\n",
      "Epochs 451/1000 - Loss: 0.0028381545562297106\n",
      "--- 0.445s ---\n",
      "Epochs 452/1000 - Loss: 0.0028339235577732325\n",
      "--- 0.447s ---\n",
      "Epochs 453/1000 - Loss: 0.0028297079261392355\n",
      "--- 0.446s ---\n",
      "Epochs 454/1000 - Loss: 0.0028255083598196507\n",
      "--- 0.443s ---\n",
      "Epochs 455/1000 - Loss: 0.0028213246259838343\n",
      "--- 0.448s ---\n",
      "Epochs 456/1000 - Loss: 0.0028171564918011427\n",
      "--- 0.447s ---\n",
      "Epochs 457/1000 - Loss: 0.0028130041901022196\n",
      "--- 0.453s ---\n",
      "Epochs 458/1000 - Loss: 0.0028088672552257776\n",
      "--- 0.456s ---\n",
      "Epochs 459/1000 - Loss: 0.002804745687171817\n",
      "--- 0.45s ---\n",
      "Epochs 460/1000 - Loss: 0.002800639485940337\n",
      "--- 0.452s ---\n",
      "Epochs 461/1000 - Loss: 0.0027965486515313387\n",
      "--- 0.453s ---\n",
      "Epochs 462/1000 - Loss: 0.002792472718283534\n",
      "--- 0.453s ---\n",
      "Epochs 463/1000 - Loss: 0.002788411919027567\n",
      "--- 0.45s ---\n",
      "Epochs 464/1000 - Loss: 0.002784366486594081\n",
      "--- 0.457s ---\n",
      "Epochs 465/1000 - Loss: 0.002780335256829858\n",
      "--- 0.448s ---\n",
      "Epochs 466/1000 - Loss: 0.0027763191610574722\n",
      "--- 0.445s ---\n",
      "Epochs 467/1000 - Loss: 0.0027723179664462805\n",
      "--- 0.446s ---\n",
      "Epochs 468/1000 - Loss: 0.0027683312073349953\n",
      "--- 0.449s ---\n",
      "Epochs 469/1000 - Loss: 0.0027643588837236166\n",
      "--- 0.459s ---\n",
      "Epochs 470/1000 - Loss: 0.0027604014612734318\n",
      "--- 0.444s ---\n",
      "Epochs 471/1000 - Loss: 0.0027564577758312225\n",
      "--- 0.457s ---\n",
      "Epochs 472/1000 - Loss: 0.002752529224380851\n",
      "--- 0.449s ---\n",
      "Epochs 473/1000 - Loss: 0.002748614177107811\n",
      "--- 0.445s ---\n",
      "Epochs 474/1000 - Loss: 0.002744713332504034\n",
      "--- 0.449s ---\n",
      "Epochs 475/1000 - Loss: 0.0027408269234001637\n",
      "--- 0.443s ---\n",
      "Epochs 476/1000 - Loss: 0.0027369537856429815\n",
      "--- 0.449s ---\n",
      "Epochs 477/1000 - Loss: 0.002733095083385706\n",
      "--- 0.449s ---\n",
      "Epochs 478/1000 - Loss: 0.0027292503509670496\n",
      "--- 0.461s ---\n",
      "Epochs 479/1000 - Loss: 0.0027254188898950815\n",
      "--- 0.457s ---\n",
      "Epochs 480/1000 - Loss: 0.0027216016314923763\n",
      "--- 0.454s ---\n",
      "Epochs 481/1000 - Loss: 0.0027177976444363594\n",
      "--- 0.447s ---\n",
      "Epochs 482/1000 - Loss: 0.0027140069287270308\n",
      "--- 0.446s ---\n",
      "Epochs 483/1000 - Loss: 0.0027102301828563213\n",
      "--- 0.451s ---\n",
      "Epochs 484/1000 - Loss: 0.0027064667083323\n",
      "--- 0.451s ---\n",
      "Epochs 485/1000 - Loss: 0.0027027162723243237\n",
      "--- 0.451s ---\n",
      "Epochs 486/1000 - Loss: 0.0026989791076630354\n",
      "--- 0.452s ---\n",
      "Epochs 487/1000 - Loss: 0.0026952549815177917\n",
      "--- 0.455s ---\n",
      "Epochs 488/1000 - Loss: 0.00269154435954988\n",
      "--- 0.442s ---\n",
      "Epochs 489/1000 - Loss: 0.0026878463104367256\n",
      "--- 0.449s ---\n",
      "Epochs 490/1000 - Loss: 0.0026841615326702595\n",
      "--- 0.448s ---\n",
      "Epochs 491/1000 - Loss: 0.0026804888620972633\n",
      "--- 0.45s ---\n",
      "Epochs 492/1000 - Loss: 0.0026768294628709555\n",
      "--- 0.452s ---\n",
      "Epochs 493/1000 - Loss: 0.002673183334991336\n",
      "--- 0.454s ---\n",
      "Epochs 494/1000 - Loss: 0.0026695490814745426\n",
      "--- 0.454s ---\n",
      "Epochs 495/1000 - Loss: 0.002665927866473794\n",
      "--- 0.454s ---\n",
      "Epochs 496/1000 - Loss: 0.0026623187586665154\n",
      "--- 0.451s ---\n",
      "Epochs 497/1000 - Loss: 0.0026587224565446377\n",
      "--- 0.463s ---\n",
      "Epochs 498/1000 - Loss: 0.00265513826161623\n",
      "--- 0.444s ---\n",
      "Epochs 499/1000 - Loss: 0.0026515668723732233\n",
      "--- 0.448s ---\n",
      "Epochs 500/1000 - Loss: 0.0026480071246623993\n",
      "--- 0.454s ---\n",
      "Epochs 501/1000 - Loss: 0.002644459716975689\n",
      "--- 0.45s ---\n",
      "Epochs 502/1000 - Loss: 0.0026409244164824486\n",
      "--- 0.453s ---\n",
      "Epochs 503/1000 - Loss: 0.0026374012231826782\n",
      "--- 0.455s ---\n",
      "Epochs 504/1000 - Loss: 0.002633890137076378\n",
      "--- 0.452s ---\n",
      "Epochs 505/1000 - Loss: 0.002630390925332904\n",
      "--- 0.447s ---\n",
      "Epochs 506/1000 - Loss: 0.002626903587952256\n",
      "--- 0.449s ---\n",
      "Epochs 507/1000 - Loss: 0.0026234276592731476\n",
      "--- 0.45s ---\n",
      "Epochs 508/1000 - Loss: 0.0026199640706181526\n",
      "--- 0.445s ---\n",
      "Epochs 509/1000 - Loss: 0.0026165118906646967\n",
      "--- 0.454s ---\n",
      "Epochs 510/1000 - Loss: 0.00261307111941278\n",
      "--- 0.447s ---\n",
      "Epochs 511/1000 - Loss: 0.0026096419896930456\n",
      "--- 0.444s ---\n",
      "Epochs 512/1000 - Loss: 0.002606224501505494\n",
      "--- 0.452s ---\n",
      "Epochs 513/1000 - Loss: 0.0026028184220194817\n",
      "--- 0.455s ---\n",
      "Epochs 514/1000 - Loss: 0.0025994235184043646\n",
      "--- 0.457s ---\n",
      "Epochs 515/1000 - Loss: 0.0025960400234907866\n",
      "--- 0.461s ---\n",
      "Epochs 516/1000 - Loss: 0.0025926679372787476\n",
      "--- 0.458s ---\n",
      "Epochs 517/1000 - Loss: 0.002589307026937604\n",
      "--- 0.456s ---\n",
      "Epochs 518/1000 - Loss: 0.002585957059636712\n",
      "--- 0.451s ---\n",
      "Epochs 519/1000 - Loss: 0.0025826182682067156\n",
      "--- 0.463s ---\n",
      "Epochs 520/1000 - Loss: 0.002579290186986327\n",
      "--- 0.453s ---\n",
      "Epochs 521/1000 - Loss: 0.002575973514467478\n",
      "--- 0.451s ---\n",
      "Epochs 522/1000 - Loss: 0.0025726675521582365\n",
      "--- 0.467s ---\n",
      "Epochs 523/1000 - Loss: 0.0025693727657198906\n",
      "--- 0.451s ---\n",
      "Epochs 524/1000 - Loss: 0.002566088456660509\n",
      "--- 0.454s ---\n",
      "Epochs 525/1000 - Loss: 0.0025628150906413794\n",
      "--- 0.452s ---\n",
      "Epochs 526/1000 - Loss: 0.0025595517363399267\n",
      "--- 0.451s ---\n",
      "Epochs 527/1000 - Loss: 0.002556299790740013\n",
      "--- 0.448s ---\n",
      "Epochs 528/1000 - Loss: 0.0025530580896884203\n",
      "--- 0.459s ---\n",
      "Epochs 529/1000 - Loss: 0.0025498270988464355\n",
      "--- 0.45s ---\n",
      "Epochs 530/1000 - Loss: 0.0025466063525527716\n",
      "--- 0.456s ---\n",
      "Epochs 531/1000 - Loss: 0.0025433958508074284\n",
      "--- 0.455s ---\n",
      "Epochs 532/1000 - Loss: 0.002540196292102337\n",
      "--- 0.452s ---\n",
      "Epochs 533/1000 - Loss: 0.0025370067451149225\n",
      "--- 0.449s ---\n",
      "Epochs 534/1000 - Loss: 0.002533827442675829\n",
      "--- 0.44s ---\n",
      "Epochs 535/1000 - Loss: 0.0025306581519544125\n",
      "--- 0.452s ---\n",
      "Epochs 536/1000 - Loss: 0.0025274991057813168\n",
      "--- 0.453s ---\n",
      "Epochs 537/1000 - Loss: 0.002524350304156542\n",
      "--- 0.46s ---\n",
      "Epochs 538/1000 - Loss: 0.0025212117470800877\n",
      "--- 0.453s ---\n",
      "Epochs 539/1000 - Loss: 0.002518082968890667\n",
      "--- 0.454s ---\n",
      "Epochs 540/1000 - Loss: 0.0025149639695882797\n",
      "--- 0.459s ---\n",
      "Epochs 541/1000 - Loss: 0.0025118549820035696\n",
      "--- 0.451s ---\n",
      "Epochs 542/1000 - Loss: 0.0025087560061365366\n",
      "--- 0.45s ---\n",
      "Epochs 543/1000 - Loss: 0.0025056665763258934\n",
      "--- 0.466s ---\n",
      "Epochs 544/1000 - Loss: 0.0025025871582329273\n",
      "--- 0.448s ---\n",
      "Epochs 545/1000 - Loss: 0.0024995170533657074\n",
      "--- 0.455s ---\n",
      "Epochs 546/1000 - Loss: 0.0024964569602161646\n",
      "--- 0.451s ---\n",
      "Epochs 547/1000 - Loss: 0.0024934066459536552\n",
      "--- 0.452s ---\n",
      "Epochs 548/1000 - Loss: 0.0024903658777475357\n",
      "--- 0.458s ---\n",
      "Epochs 549/1000 - Loss: 0.0024873341899365187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.448s ---\n",
      "Epochs 550/1000 - Loss: 0.002484312281012535\n",
      "--- 0.46s ---\n",
      "Epochs 551/1000 - Loss: 0.002481299452483654\n",
      "--- 0.45s ---\n",
      "Epochs 552/1000 - Loss: 0.0024782964028418064\n",
      "--- 0.451s ---\n",
      "Epochs 553/1000 - Loss: 0.002475302666425705\n",
      "--- 0.45s ---\n",
      "Epochs 554/1000 - Loss: 0.002472318010404706\n",
      "--- 0.453s ---\n",
      "Epochs 555/1000 - Loss: 0.002469342667609453\n",
      "--- 0.45s ---\n",
      "Epochs 556/1000 - Loss: 0.00246637687087059\n",
      "--- 0.446s ---\n",
      "Epochs 557/1000 - Loss: 0.0024634196888655424\n",
      "--- 0.439s ---\n",
      "Epochs 558/1000 - Loss: 0.002460471587255597\n",
      "--- 0.448s ---\n",
      "Epochs 559/1000 - Loss: 0.002457532798871398\n",
      "--- 0.449s ---\n",
      "Epochs 560/1000 - Loss: 0.0024546030908823013\n",
      "--- 0.447s ---\n",
      "Epochs 561/1000 - Loss: 0.002451682463288307\n",
      "--- 0.449s ---\n",
      "Epochs 562/1000 - Loss: 0.002448770683258772\n",
      "--- 0.443s ---\n",
      "Epochs 563/1000 - Loss: 0.002445867517963052\n",
      "--- 0.447s ---\n",
      "Epochs 564/1000 - Loss: 0.002442973665893078\n",
      "--- 0.446s ---\n",
      "Epochs 565/1000 - Loss: 0.0024400881957262754\n",
      "--- 0.448s ---\n",
      "Epochs 566/1000 - Loss: 0.0024372113402932882\n",
      "--- 0.447s ---\n",
      "Epochs 567/1000 - Loss: 0.002434343798086047\n",
      "--- 0.444s ---\n",
      "Epochs 568/1000 - Loss: 0.002431484404951334\n",
      "--- 0.449s ---\n",
      "Epochs 569/1000 - Loss: 0.0024286340922117233\n",
      "--- 0.445s ---\n",
      "Epochs 570/1000 - Loss: 0.002425792161375284\n",
      "--- 0.452s ---\n",
      "Epochs 571/1000 - Loss: 0.0024229586124420166\n",
      "--- 0.449s ---\n",
      "Epochs 572/1000 - Loss: 0.0024201341439038515\n",
      "--- 0.447s ---\n",
      "Epochs 573/1000 - Loss: 0.002417317358776927\n",
      "--- 0.451s ---\n",
      "Epochs 574/1000 - Loss: 0.0024145094212144613\n",
      "--- 0.445s ---\n",
      "Epochs 575/1000 - Loss: 0.002411710098385811\n",
      "--- 0.455s ---\n",
      "Epochs 576/1000 - Loss: 0.0024089189246296883\n",
      "--- 0.45s ---\n",
      "Epochs 577/1000 - Loss: 0.0024061358999460936\n",
      "--- 0.45s ---\n",
      "Epochs 578/1000 - Loss: 0.002403361489996314\n",
      "--- 0.462s ---\n",
      "Epochs 579/1000 - Loss: 0.0024005952291190624\n",
      "--- 0.456s ---\n",
      "Epochs 580/1000 - Loss: 0.0023978366516530514\n",
      "--- 0.452s ---\n",
      "Epochs 581/1000 - Loss: 0.002395086921751499\n",
      "--- 0.446s ---\n",
      "Epochs 582/1000 - Loss: 0.0023923448752611876\n",
      "--- 0.447s ---\n",
      "Epochs 583/1000 - Loss: 0.002389610977843404\n",
      "--- 0.447s ---\n",
      "Epochs 584/1000 - Loss: 0.002386885229498148\n",
      "--- 0.453s ---\n",
      "Epochs 585/1000 - Loss: 0.0023841673973947763\n",
      "--- 0.451s ---\n",
      "Epochs 586/1000 - Loss: 0.0023814579471945763\n",
      "--- 0.45s ---\n",
      "Epochs 587/1000 - Loss: 0.0023787557147443295\n",
      "--- 0.452s ---\n",
      "Epochs 588/1000 - Loss: 0.002376062097027898\n",
      "--- 0.444s ---\n",
      "Epochs 589/1000 - Loss: 0.002373375929892063\n",
      "--- 0.443s ---\n",
      "Epochs 590/1000 - Loss: 0.0023706976789981127\n",
      "--- 0.444s ---\n",
      "Epochs 591/1000 - Loss: 0.002368027111515403\n",
      "--- 0.448s ---\n",
      "Epochs 592/1000 - Loss: 0.0023653642274439335\n",
      "--- 0.449s ---\n",
      "Epochs 593/1000 - Loss: 0.0023627092596143484\n",
      "--- 0.446s ---\n",
      "Epochs 594/1000 - Loss: 0.002360061975196004\n",
      "--- 0.448s ---\n",
      "Epochs 595/1000 - Loss: 0.0023574223741889\n",
      "--- 0.452s ---\n",
      "Epochs 596/1000 - Loss: 0.002354790223762393\n",
      "--- 0.455s ---\n",
      "Epochs 597/1000 - Loss: 0.0023521657567471266\n",
      "--- 0.453s ---\n",
      "Epochs 598/1000 - Loss: 0.002349548740312457\n",
      "--- 0.452s ---\n",
      "Epochs 599/1000 - Loss: 0.0023469391744583845\n",
      "--- 0.445s ---\n",
      "Epochs 600/1000 - Loss: 0.002344337059184909\n",
      "--- 0.452s ---\n",
      "Epochs 601/1000 - Loss: 0.002341742627322674\n",
      "--- 0.452s ---\n",
      "Epochs 602/1000 - Loss: 0.002339155413210392\n",
      "--- 0.448s ---\n",
      "Epochs 603/1000 - Loss: 0.002336575649678707\n",
      "--- 0.448s ---\n",
      "Epochs 604/1000 - Loss: 0.0023340031038969755\n",
      "--- 0.459s ---\n",
      "Epochs 605/1000 - Loss: 0.002331438008695841\n",
      "--- 0.448s ---\n",
      "Epochs 606/1000 - Loss: 0.0023288801312446594\n",
      "--- 0.458s ---\n",
      "Epochs 607/1000 - Loss: 0.002326329704374075\n",
      "--- 0.45s ---\n",
      "Epochs 608/1000 - Loss: 0.0023237860295921564\n",
      "--- 0.446s ---\n",
      "Epochs 609/1000 - Loss: 0.002321249805390835\n",
      "--- 0.456s ---\n",
      "Epochs 610/1000 - Loss: 0.002318720566108823\n",
      "--- 0.458s ---\n",
      "Epochs 611/1000 - Loss: 0.0023161983117461205\n",
      "--- 0.439s ---\n",
      "Epochs 612/1000 - Loss: 0.002313683507964015\n",
      "--- 0.451s ---\n",
      "Epochs 613/1000 - Loss: 0.0023111754562705755\n",
      "--- 0.45s ---\n",
      "Epochs 614/1000 - Loss: 0.0023086746223270893\n",
      "--- 0.449s ---\n",
      "Epochs 615/1000 - Loss: 0.0023061807733029127\n",
      "--- 0.45s ---\n",
      "Epochs 616/1000 - Loss: 0.002303693676367402\n",
      "--- 0.451s ---\n",
      "Epochs 617/1000 - Loss: 0.0023012137971818447\n",
      "--- 0.448s ---\n",
      "Epochs 618/1000 - Loss: 0.0022987404372543097\n",
      "--- 0.447s ---\n",
      "Epochs 619/1000 - Loss: 0.002296274062246084\n",
      "--- 0.45s ---\n",
      "Epochs 620/1000 - Loss: 0.0022938144393265247\n",
      "--- 0.444s ---\n",
      "Epochs 621/1000 - Loss: 0.0022913615684956312\n",
      "--- 0.451s ---\n",
      "Epochs 622/1000 - Loss: 0.0022889156825840473\n",
      "--- 0.443s ---\n",
      "Epochs 623/1000 - Loss: 0.002286476083099842\n",
      "--- 0.446s ---\n",
      "Epochs 624/1000 - Loss: 0.0022840439341962337\n",
      "--- 0.452s ---\n",
      "Epochs 625/1000 - Loss: 0.0022816178388893604\n",
      "--- 0.446s ---\n",
      "Epochs 626/1000 - Loss: 0.0022791989613324404\n",
      "--- 0.444s ---\n",
      "Epochs 627/1000 - Loss: 0.0022767861373722553\n",
      "--- 0.451s ---\n",
      "Epochs 628/1000 - Loss: 0.0022743800655007362\n",
      "--- 0.451s ---\n",
      "Epochs 629/1000 - Loss: 0.0022719805128872395\n",
      "--- 0.451s ---\n",
      "Epochs 630/1000 - Loss: 0.002269587479531765\n",
      "--- 0.449s ---\n",
      "Epochs 631/1000 - Loss: 0.0022672011982649565\n",
      "--- 0.444s ---\n",
      "Epochs 632/1000 - Loss: 0.002264820970594883\n",
      "--- 0.469s ---\n",
      "Epochs 633/1000 - Loss: 0.0022624472621828318\n",
      "--- 0.45s ---\n",
      "Epochs 634/1000 - Loss: 0.0022600803058594465\n",
      "--- 0.447s ---\n",
      "Epochs 635/1000 - Loss: 0.00225771963596344\n",
      "--- 0.454s ---\n",
      "Epochs 636/1000 - Loss: 0.002255365252494812\n",
      "--- 0.453s ---\n",
      "Epochs 637/1000 - Loss: 0.0022530171554535627\n",
      "--- 0.452s ---\n",
      "Epochs 638/1000 - Loss: 0.0022506751120090485\n",
      "--- 0.446s ---\n",
      "Epochs 639/1000 - Loss: 0.0022483398206532\n",
      "--- 0.45s ---\n",
      "Epochs 640/1000 - Loss: 0.002246010350063443\n",
      "--- 0.453s ---\n",
      "Epochs 641/1000 - Loss: 0.0022436873987317085\n",
      "--- 0.45s ---\n",
      "Epochs 642/1000 - Loss: 0.002241370500996709\n",
      "--- 0.442s ---\n",
      "Epochs 643/1000 - Loss: 0.002239059656858444\n",
      "--- 0.44s ---\n",
      "Epochs 644/1000 - Loss: 0.002236755099147558\n",
      "--- 0.437s ---\n",
      "Epochs 645/1000 - Loss: 0.002234456595033407\n",
      "--- 0.446s ---\n",
      "Epochs 646/1000 - Loss: 0.002232164144515991\n",
      "--- 0.446s ---\n",
      "Epochs 647/1000 - Loss: 0.002229877980425954\n",
      "--- 0.445s ---\n",
      "Epochs 648/1000 - Loss: 0.002227597637102008\n",
      "--- 0.446s ---\n",
      "Epochs 649/1000 - Loss: 0.0022253235802054405\n",
      "--- 0.455s ---\n",
      "Epochs 650/1000 - Loss: 0.002223055111244321\n",
      "--- 0.446s ---\n",
      "Epochs 651/1000 - Loss: 0.0022207926958799362\n",
      "--- 0.445s ---\n",
      "Epochs 652/1000 - Loss: 0.0022185363341122866\n",
      "--- 0.459s ---\n",
      "Epochs 653/1000 - Loss: 0.0022162857931107283\n",
      "--- 0.45s ---\n",
      "Epochs 654/1000 - Loss: 0.0022140408400446177\n",
      "--- 0.448s ---\n",
      "Epochs 655/1000 - Loss: 0.0022118021734058857\n",
      "--- 0.447s ---\n",
      "Epochs 656/1000 - Loss: 0.002209569327533245\n",
      "--- 0.451s ---\n",
      "Epochs 657/1000 - Loss: 0.002207342069596052\n",
      "--- 0.449s ---\n",
      "Epochs 658/1000 - Loss: 0.0022051206324249506\n",
      "--- 0.451s ---\n",
      "Epochs 659/1000 - Loss: 0.0022029047831892967\n",
      "--- 0.448s ---\n",
      "Epochs 660/1000 - Loss: 0.002200694754719734\n",
      "--- 0.463s ---\n",
      "Epochs 661/1000 - Loss: 0.002198490547016263\n",
      "--- 0.448s ---\n",
      "Epochs 662/1000 - Loss: 0.002196292160078883\n",
      "--- 0.449s ---\n",
      "Epochs 663/1000 - Loss: 0.002194099361076951\n",
      "--- 0.443s ---\n",
      "Epochs 664/1000 - Loss: 0.002191911917179823\n",
      "--- 0.457s ---\n",
      "Epochs 665/1000 - Loss: 0.002189730294048786\n",
      "--- 0.445s ---\n",
      "Epochs 666/1000 - Loss: 0.0021875544916838408\n",
      "--- 0.449s ---\n",
      "Epochs 667/1000 - Loss: 0.0021853838115930557\n",
      "--- 0.456s ---\n",
      "Epochs 668/1000 - Loss: 0.0021832187194377184\n",
      "--- 0.446s ---\n",
      "Epochs 669/1000 - Loss: 0.0021810594480484724\n",
      "--- 0.454s ---\n",
      "Epochs 670/1000 - Loss: 0.0021789055317640305\n",
      "--- 0.449s ---\n",
      "Epochs 671/1000 - Loss: 0.002176756737753749\n",
      "--- 0.453s ---\n",
      "Epochs 672/1000 - Loss: 0.002174613531678915\n",
      "--- 0.448s ---\n",
      "Epochs 673/1000 - Loss: 0.002172475913539529\n",
      "--- 0.46s ---\n",
      "Epochs 674/1000 - Loss: 0.0021703436505049467\n",
      "--- 0.449s ---\n",
      "Epochs 675/1000 - Loss: 0.0021682169754058123\n",
      "--- 0.45s ---\n",
      "Epochs 676/1000 - Loss: 0.002166095422580838\n",
      "--- 0.467s ---\n",
      "Epochs 677/1000 - Loss: 0.0021639789920300245\n",
      "--- 0.454s ---\n",
      "Epochs 678/1000 - Loss: 0.0021618681494146585\n",
      "--- 0.454s ---\n",
      "Epochs 679/1000 - Loss: 0.002159762429073453\n",
      "--- 0.453s ---\n",
      "Epochs 680/1000 - Loss: 0.0021576620638370514\n",
      "--- 0.45s ---\n",
      "Epochs 681/1000 - Loss: 0.002155567053705454\n",
      "--- 0.455s ---\n",
      "Epochs 682/1000 - Loss: 0.002153476933017373\n",
      "--- 0.453s ---\n",
      "Epochs 683/1000 - Loss: 0.00215139240026474\n",
      "--- 0.451s ---\n",
      "Epochs 684/1000 - Loss: 0.0021493129897862673\n",
      "--- 0.451s ---\n",
      "Epochs 685/1000 - Loss: 0.0021472384687513113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.447s ---\n",
      "Epochs 686/1000 - Loss: 0.0021451693028211594\n",
      "--- 0.447s ---\n",
      "Epochs 687/1000 - Loss: 0.002143105259165168\n",
      "--- 0.448s ---\n",
      "Epochs 688/1000 - Loss: 0.0021410463377833366\n",
      "--- 0.456s ---\n",
      "Epochs 689/1000 - Loss: 0.002138992305845022\n",
      "--- 0.463s ---\n",
      "Epochs 690/1000 - Loss: 0.0021369431633502245\n",
      "--- 0.45s ---\n",
      "Epochs 691/1000 - Loss: 0.002134899375960231\n",
      "--- 0.455s ---\n",
      "Epochs 692/1000 - Loss: 0.002132860478013754\n",
      "--- 0.455s ---\n",
      "Epochs 693/1000 - Loss: 0.0021308267023414373\n",
      "--- 0.448s ---\n",
      "Epochs 694/1000 - Loss: 0.002128797583281994\n",
      "--- 0.45s ---\n",
      "Epochs 695/1000 - Loss: 0.0021267735864967108\n",
      "--- 0.452s ---\n",
      "Epochs 696/1000 - Loss: 0.002124754711985588\n",
      "--- 0.445s ---\n",
      "Epochs 697/1000 - Loss: 0.002122740726917982\n",
      "--- 0.45s ---\n",
      "Epochs 698/1000 - Loss: 0.002120731631293893\n",
      "--- 0.452s ---\n",
      "Epochs 699/1000 - Loss: 0.002118726959452033\n",
      "--- 0.451s ---\n",
      "Epochs 700/1000 - Loss: 0.00211672717705369\n",
      "--- 0.449s ---\n",
      "Epochs 701/1000 - Loss: 0.0021147329825907946\n",
      "--- 0.443s ---\n",
      "Epochs 702/1000 - Loss: 0.002112742979079485\n",
      "--- 0.449s ---\n",
      "Epochs 703/1000 - Loss: 0.0021107576321810484\n",
      "--- 0.446s ---\n",
      "Epochs 704/1000 - Loss: 0.002108777640387416\n",
      "--- 0.449s ---\n",
      "Epochs 705/1000 - Loss: 0.002106801839545369\n",
      "--- 0.454s ---\n",
      "Epochs 706/1000 - Loss: 0.002104830928146839\n",
      "--- 0.445s ---\n",
      "Epochs 707/1000 - Loss: 0.0021028651390224695\n",
      "--- 0.451s ---\n",
      "Epochs 708/1000 - Loss: 0.002100903308019042\n",
      "--- 0.446s ---\n",
      "Epochs 709/1000 - Loss: 0.002098946599289775\n",
      "--- 0.451s ---\n",
      "Epochs 710/1000 - Loss: 0.0020969947800040245\n",
      "--- 0.452s ---\n",
      "Epochs 711/1000 - Loss: 0.00209504715166986\n",
      "--- 0.452s ---\n",
      "Epochs 712/1000 - Loss: 0.002093104412779212\n",
      "--- 0.45s ---\n",
      "Epochs 713/1000 - Loss: 0.0020911660976707935\n",
      "--- 0.453s ---\n",
      "Epochs 714/1000 - Loss: 0.002089232672005892\n",
      "--- 0.453s ---\n",
      "Epochs 715/1000 - Loss: 0.002087303437292576\n",
      "--- 0.448s ---\n",
      "Epochs 716/1000 - Loss: 0.002085378859192133\n",
      "--- 0.457s ---\n",
      "Epochs 717/1000 - Loss: 0.002083458937704563\n",
      "--- 0.448s ---\n",
      "Epochs 718/1000 - Loss: 0.0020815434399992228\n",
      "--- 0.445s ---\n",
      "Epochs 719/1000 - Loss: 0.002079632366076112\n",
      "--- 0.472s ---\n",
      "Epochs 720/1000 - Loss: 0.0020777257159352303\n",
      "--- 0.457s ---\n",
      "Epochs 721/1000 - Loss: 0.0020758239552378654\n",
      "--- 0.45s ---\n",
      "Epochs 722/1000 - Loss: 0.0020739261526614428\n",
      "--- 0.445s ---\n",
      "Epochs 723/1000 - Loss: 0.002072033006697893\n",
      "--- 0.445s ---\n",
      "Epochs 724/1000 - Loss: 0.002070144284516573\n",
      "--- 0.451s ---\n",
      "Epochs 725/1000 - Loss: 0.0020682597532868385\n",
      "--- 0.456s ---\n",
      "Epochs 726/1000 - Loss: 0.002066379878669977\n",
      "--- 0.452s ---\n",
      "Epochs 727/1000 - Loss: 0.002064503962174058\n",
      "--- 0.451s ---\n",
      "Epochs 728/1000 - Loss: 0.0020626329351216555\n",
      "--- 0.449s ---\n",
      "Epochs 729/1000 - Loss: 0.002060765866190195\n",
      "--- 0.44s ---\n",
      "Epochs 730/1000 - Loss: 0.0020589029882103205\n",
      "--- 0.455s ---\n",
      "Epochs 731/1000 - Loss: 0.002057044766843319\n",
      "--- 0.454s ---\n",
      "Epochs 732/1000 - Loss: 0.0020551905035972595\n",
      "--- 0.452s ---\n",
      "Epochs 733/1000 - Loss: 0.0020533406641334295\n",
      "--- 0.444s ---\n",
      "Epochs 734/1000 - Loss: 0.0020514950156211853\n",
      "--- 0.457s ---\n",
      "Epochs 735/1000 - Loss: 0.002049653558060527\n",
      "--- 0.444s ---\n",
      "Epochs 736/1000 - Loss: 0.002047816524282098\n",
      "--- 0.45s ---\n",
      "Epochs 737/1000 - Loss: 0.002045983448624611\n",
      "--- 0.452s ---\n",
      "Epochs 738/1000 - Loss: 0.0020441545639187098\n",
      "--- 0.447s ---\n",
      "Epochs 739/1000 - Loss: 0.0020423296373337507\n",
      "--- 0.447s ---\n",
      "Epochs 740/1000 - Loss: 0.002040509134531021\n",
      "--- 0.447s ---\n",
      "Epochs 741/1000 - Loss: 0.0020386928226798773\n",
      "--- 0.452s ---\n",
      "Epochs 742/1000 - Loss: 0.0020368804689496756\n",
      "--- 0.453s ---\n",
      "Epochs 743/1000 - Loss: 0.0020350723061710596\n",
      "--- 0.449s ---\n",
      "Epochs 744/1000 - Loss: 0.0020332681015133858\n",
      "--- 0.456s ---\n",
      "Epochs 745/1000 - Loss: 0.002031467854976654\n",
      "--- 0.457s ---\n",
      "Epochs 746/1000 - Loss: 0.0020296720322221518\n",
      "--- 0.458s ---\n",
      "Epochs 747/1000 - Loss: 0.0020278801675885916\n",
      "--- 0.467s ---\n",
      "Epochs 748/1000 - Loss: 0.0020260922610759735\n",
      "--- 0.445s ---\n",
      "Epochs 749/1000 - Loss: 0.002024308079853654\n",
      "--- 0.459s ---\n",
      "Epochs 750/1000 - Loss: 0.00202252808958292\n",
      "--- 0.45s ---\n",
      "Epochs 751/1000 - Loss: 0.0020207520574331284\n",
      "--- 0.455s ---\n",
      "Epochs 752/1000 - Loss: 0.0020189799834042788\n",
      "--- 0.45s ---\n",
      "Epochs 753/1000 - Loss: 0.002017212100327015\n",
      "--- 0.457s ---\n",
      "Epochs 754/1000 - Loss: 0.0020154479425400496\n",
      "--- 0.458s ---\n",
      "Epochs 755/1000 - Loss: 0.0020136877428740263\n",
      "--- 0.459s ---\n",
      "Epochs 756/1000 - Loss: 0.0020119312684983015\n",
      "--- 0.452s ---\n",
      "Epochs 757/1000 - Loss: 0.002010178752243519\n",
      "--- 0.444s ---\n",
      "Epochs 758/1000 - Loss: 0.002008430426940322\n",
      "--- 0.447s ---\n",
      "Epochs 759/1000 - Loss: 0.00200668559409678\n",
      "--- 0.449s ---\n",
      "Epochs 760/1000 - Loss: 0.00200494471937418\n",
      "--- 0.449s ---\n",
      "Epochs 761/1000 - Loss: 0.0020032075699418783\n",
      "--- 0.451s ---\n",
      "Epochs 762/1000 - Loss: 0.002001474378630519\n",
      "--- 0.455s ---\n",
      "Epochs 763/1000 - Loss: 0.001999744912609458\n",
      "--- 0.451s ---\n",
      "Epochs 764/1000 - Loss: 0.0019980191718786955\n",
      "--- 0.447s ---\n",
      "Epochs 765/1000 - Loss: 0.0019962971564382315\n",
      "--- 0.449s ---\n",
      "Epochs 766/1000 - Loss: 0.0019945790991187096\n",
      "--- 0.447s ---\n",
      "Epochs 767/1000 - Loss: 0.001992864767089486\n",
      "--- 0.45s ---\n",
      "Epochs 768/1000 - Loss: 0.001991154160350561\n",
      "--- 0.458s ---\n",
      "Epochs 769/1000 - Loss: 0.0019894472789019346\n",
      "--- 0.452s ---\n",
      "Epochs 770/1000 - Loss: 0.001987743889912963\n",
      "--- 0.452s ---\n",
      "Epochs 771/1000 - Loss: 0.0019860444590449333\n",
      "--- 0.458s ---\n",
      "Epochs 772/1000 - Loss: 0.0019843485206365585\n",
      "--- 0.45s ---\n",
      "Epochs 773/1000 - Loss: 0.001982656540349126\n",
      "--- 0.451s ---\n",
      "Epochs 774/1000 - Loss: 0.0019809678196907043\n",
      "--- 0.454s ---\n",
      "Epochs 775/1000 - Loss: 0.001979283057153225\n",
      "--- 0.448s ---\n",
      "Epochs 776/1000 - Loss: 0.0019776017870754004\n",
      "--- 0.469s ---\n",
      "Epochs 777/1000 - Loss: 0.0019759240094572306\n",
      "--- 0.457s ---\n",
      "Epochs 778/1000 - Loss: 0.001974250189960003\n",
      "--- 0.468s ---\n",
      "Epochs 779/1000 - Loss: 0.0019725796300917864\n",
      "--- 0.45s ---\n",
      "Epochs 780/1000 - Loss: 0.0019709125626832247\n",
      "--- 0.455s ---\n",
      "Epochs 781/1000 - Loss: 0.0019692492205649614\n",
      "--- 0.459s ---\n",
      "Epochs 782/1000 - Loss: 0.0019675896037369967\n",
      "--- 0.457s ---\n",
      "Epochs 783/1000 - Loss: 0.001965933246538043\n",
      "--- 0.47s ---\n",
      "Epochs 784/1000 - Loss: 0.001964280381798744\n",
      "--- 0.454s ---\n",
      "Epochs 785/1000 - Loss: 0.001962631242349744\n",
      "--- 0.455s ---\n",
      "Epochs 786/1000 - Loss: 0.0019609855953603983\n",
      "--- 0.449s ---\n",
      "Epochs 787/1000 - Loss: 0.0019593429751694202\n",
      "--- 0.448s ---\n",
      "Epochs 788/1000 - Loss: 0.001957704545930028\n",
      "--- 0.454s ---\n",
      "Epochs 789/1000 - Loss: 0.001956069376319647\n",
      "--- 0.461s ---\n",
      "Epochs 790/1000 - Loss: 0.001954437233507633\n",
      "--- 0.457s ---\n",
      "Epochs 791/1000 - Loss: 0.001952808815985918\n",
      "--- 0.452s ---\n",
      "Epochs 792/1000 - Loss: 0.0019511838909238577\n",
      "--- 0.459s ---\n",
      "Epochs 793/1000 - Loss: 0.0019495622254908085\n",
      "--- 0.454s ---\n",
      "Epochs 794/1000 - Loss: 0.001947944168932736\n",
      "--- 0.453s ---\n",
      "Epochs 795/1000 - Loss: 0.0019463291391730309\n",
      "--- 0.46s ---\n",
      "Epochs 796/1000 - Loss: 0.001944717951118946\n",
      "--- 0.463s ---\n",
      "Epochs 797/1000 - Loss: 0.001943109673447907\n",
      "--- 0.449s ---\n",
      "Epochs 798/1000 - Loss: 0.0019415048882365227\n",
      "--- 0.456s ---\n",
      "Epochs 799/1000 - Loss: 0.001939903711900115\n",
      "--- 0.451s ---\n",
      "Epochs 800/1000 - Loss: 0.0019383055623620749\n",
      "--- 0.449s ---\n",
      "Epochs 801/1000 - Loss: 0.0019367107888683677\n",
      "--- 0.462s ---\n",
      "Epochs 802/1000 - Loss: 0.0019351196242496371\n",
      "--- 0.447s ---\n",
      "Epochs 803/1000 - Loss: 0.0019335313700139523\n",
      "--- 0.451s ---\n",
      "Epochs 804/1000 - Loss: 0.0019319466082379222\n",
      "--- 0.458s ---\n",
      "Epochs 805/1000 - Loss: 0.0019303649896755815\n",
      "--- 0.461s ---\n",
      "Epochs 806/1000 - Loss: 0.0019287867471575737\n",
      "--- 0.451s ---\n",
      "Epochs 807/1000 - Loss: 0.0019272116478532553\n",
      "--- 0.468s ---\n",
      "Epochs 808/1000 - Loss: 0.0019256399245932698\n",
      "--- 0.462s ---\n",
      "Epochs 809/1000 - Loss: 0.0019240713445469737\n",
      "--- 0.447s ---\n",
      "Epochs 810/1000 - Loss: 0.001922505907714367\n",
      "--- 0.457s ---\n",
      "Epochs 811/1000 - Loss: 0.0019209436140954494\n",
      "--- 0.449s ---\n",
      "Epochs 812/1000 - Loss: 0.0019193848129361868\n",
      "--- 0.458s ---\n",
      "Epochs 813/1000 - Loss: 0.0019178290385752916\n",
      "--- 0.46s ---\n",
      "Epochs 814/1000 - Loss: 0.0019162764074280858\n",
      "--- 0.454s ---\n",
      "Epochs 815/1000 - Loss: 0.0019147270359098911\n",
      "--- 0.457s ---\n",
      "Epochs 816/1000 - Loss: 0.0019131808076053858\n",
      "--- 0.463s ---\n",
      "Epochs 817/1000 - Loss: 0.001911637489683926\n",
      "--- 0.449s ---\n",
      "Epochs 818/1000 - Loss: 0.0019100976642221212\n",
      "--- 0.459s ---\n",
      "Epochs 819/1000 - Loss: 0.0019085606327280402\n",
      "--- 0.459s ---\n",
      "Epochs 820/1000 - Loss: 0.0019070267444476485\n",
      "--- 0.45s ---\n",
      "Epochs 821/1000 - Loss: 0.001905496115796268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.459s ---\n",
      "Epochs 822/1000 - Loss: 0.0019039686303585768\n",
      "--- 0.459s ---\n",
      "Epochs 823/1000 - Loss: 0.0019024440553039312\n",
      "--- 0.459s ---\n",
      "Epochs 824/1000 - Loss: 0.001900922623462975\n",
      "--- 0.445s ---\n",
      "Epochs 825/1000 - Loss: 0.0018994042184203863\n",
      "--- 0.453s ---\n",
      "Epochs 826/1000 - Loss: 0.001897888956591487\n",
      "--- 0.453s ---\n",
      "Epochs 827/1000 - Loss: 0.0018963764887303114\n",
      "--- 0.452s ---\n",
      "Epochs 828/1000 - Loss: 0.001894867280498147\n",
      "--- 0.454s ---\n",
      "Epochs 829/1000 - Loss: 0.0018933610990643501\n",
      "--- 0.454s ---\n",
      "Epochs 830/1000 - Loss: 0.001891857711598277\n",
      "--- 0.457s ---\n",
      "Epochs 831/1000 - Loss: 0.0018903575837612152\n",
      "--- 0.452s ---\n",
      "Epochs 832/1000 - Loss: 0.001888860366307199\n",
      "--- 0.45s ---\n",
      "Epochs 833/1000 - Loss: 0.0018873660592362285\n",
      "--- 0.461s ---\n",
      "Epochs 834/1000 - Loss: 0.0018858747789636254\n",
      "--- 0.466s ---\n",
      "Epochs 835/1000 - Loss: 0.001884386409074068\n",
      "--- 0.465s ---\n",
      "Epochs 836/1000 - Loss: 0.0018829009495675564\n",
      "--- 0.453s ---\n",
      "Epochs 837/1000 - Loss: 0.001881418633274734\n",
      "--- 0.459s ---\n",
      "Epochs 838/1000 - Loss: 0.0018799389945343137\n",
      "--- 0.457s ---\n",
      "Epochs 839/1000 - Loss: 0.001878462266176939\n",
      "--- 0.455s ---\n",
      "Epochs 840/1000 - Loss: 0.0018769886810332537\n",
      "--- 0.457s ---\n",
      "Epochs 841/1000 - Loss: 0.0018755178898572922\n",
      "--- 0.457s ---\n",
      "Epochs 842/1000 - Loss: 0.0018740501254796982\n",
      "--- 0.45s ---\n",
      "Epochs 843/1000 - Loss: 0.0018725848058238626\n",
      "--- 0.457s ---\n",
      "Epochs 844/1000 - Loss: 0.001871122745797038\n",
      "--- 0.461s ---\n",
      "Epochs 845/1000 - Loss: 0.0018696635961532593\n",
      "--- 0.453s ---\n",
      "Epochs 846/1000 - Loss: 0.0018682070076465607\n",
      "--- 0.459s ---\n",
      "Epochs 847/1000 - Loss: 0.0018667533295229077\n",
      "--- 0.448s ---\n",
      "Epochs 848/1000 - Loss: 0.0018653026781976223\n",
      "--- 0.452s ---\n",
      "Epochs 849/1000 - Loss: 0.0018638548208400607\n",
      "--- 0.455s ---\n",
      "Epochs 850/1000 - Loss: 0.0018624096410349011\n",
      "--- 0.458s ---\n",
      "Epochs 851/1000 - Loss: 0.0018609672551974654\n",
      "--- 0.456s ---\n",
      "Epochs 852/1000 - Loss: 0.0018595276633277535\n",
      "--- 0.461s ---\n",
      "Epochs 853/1000 - Loss: 0.001858091214671731\n",
      "--- 0.452s ---\n",
      "Epochs 854/1000 - Loss: 0.0018566573271527886\n",
      "--- 0.451s ---\n",
      "Epochs 855/1000 - Loss: 0.0018552258843556046\n",
      "--- 0.455s ---\n",
      "Epochs 856/1000 - Loss: 0.0018537977011874318\n",
      "--- 0.449s ---\n",
      "Epochs 857/1000 - Loss: 0.0018523719627410173\n",
      "--- 0.454s ---\n",
      "Epochs 858/1000 - Loss: 0.0018509490182623267\n",
      "--- 0.454s ---\n",
      "Epochs 859/1000 - Loss: 0.0018495289841666818\n",
      "--- 0.457s ---\n",
      "Epochs 860/1000 - Loss: 0.0018481113947927952\n",
      "--- 0.447s ---\n",
      "Epochs 861/1000 - Loss: 0.0018466967158019543\n",
      "--- 0.453s ---\n",
      "Epochs 862/1000 - Loss: 0.0018452845979481936\n",
      "--- 0.45s ---\n",
      "Epochs 863/1000 - Loss: 0.0018438756233081222\n",
      "--- 0.504s ---\n",
      "Epochs 864/1000 - Loss: 0.0018424688605591655\n",
      "--- 0.467s ---\n",
      "Epochs 865/1000 - Loss: 0.0018410652410238981\n",
      "--- 0.451s ---\n",
      "Epochs 866/1000 - Loss: 0.0018396637169644237\n",
      "--- 0.454s ---\n",
      "Epochs 867/1000 - Loss: 0.0018382653361186385\n",
      "--- 0.452s ---\n",
      "Epochs 868/1000 - Loss: 0.0018368693999946117\n",
      "--- 0.455s ---\n",
      "Epochs 869/1000 - Loss: 0.0018354760250076652\n",
      "--- 0.449s ---\n",
      "Epochs 870/1000 - Loss: 0.0018340855604037642\n",
      "--- 0.451s ---\n",
      "Epochs 871/1000 - Loss: 0.0018326976569369435\n",
      "--- 0.457s ---\n",
      "Epochs 872/1000 - Loss: 0.001831312314607203\n",
      "--- 0.454s ---\n",
      "Epochs 873/1000 - Loss: 0.0018299294169992208\n",
      "--- 0.46s ---\n",
      "Epochs 874/1000 - Loss: 0.0018285494297742844\n",
      "--- 0.463s ---\n",
      "Epochs 875/1000 - Loss: 0.001827172003686428\n",
      "--- 0.454s ---\n",
      "Epochs 876/1000 - Loss: 0.0018257970223203301\n",
      "--- 0.446s ---\n",
      "Epochs 877/1000 - Loss: 0.0018244247185066342\n",
      "--- 0.453s ---\n",
      "Epochs 878/1000 - Loss: 0.0018230550922453403\n",
      "--- 0.46s ---\n",
      "Epochs 879/1000 - Loss: 0.001821687794290483\n",
      "--- 0.45s ---\n",
      "Epochs 880/1000 - Loss: 0.0018203231738880277\n",
      "--- 0.454s ---\n",
      "Epochs 881/1000 - Loss: 0.0018189611146226525\n",
      "--- 0.45s ---\n",
      "Epochs 882/1000 - Loss: 0.0018176017329096794\n",
      "--- 0.445s ---\n",
      "Epochs 883/1000 - Loss: 0.0018162446795031428\n",
      "--- 0.449s ---\n",
      "Epochs 884/1000 - Loss: 0.0018148901872336864\n",
      "--- 0.448s ---\n",
      "Epochs 885/1000 - Loss: 0.0018135382561013103\n",
      "--- 0.449s ---\n",
      "Epochs 886/1000 - Loss: 0.001812189118936658\n",
      "--- 0.453s ---\n",
      "Epochs 887/1000 - Loss: 0.0018108421936631203\n",
      "--- 0.447s ---\n",
      "Epochs 888/1000 - Loss: 0.0018094975966960192\n",
      "--- 0.45s ---\n",
      "Epochs 889/1000 - Loss: 0.0018081559101119637\n",
      "--- 0.454s ---\n",
      "Epochs 890/1000 - Loss: 0.0018068165518343449\n",
      "--- 0.456s ---\n",
      "Epochs 891/1000 - Loss: 0.0018054795218631625\n",
      "--- 0.457s ---\n",
      "Epochs 892/1000 - Loss: 0.0018041451694443822\n",
      "--- 0.461s ---\n",
      "Epochs 893/1000 - Loss: 0.0018028132617473602\n",
      "--- 0.46s ---\n",
      "Epochs 894/1000 - Loss: 0.001801483565941453\n",
      "--- 0.47s ---\n",
      "Epochs 895/1000 - Loss: 0.0018001565476879478\n",
      "--- 0.462s ---\n",
      "Epochs 896/1000 - Loss: 0.0017988317413255572\n",
      "--- 0.452s ---\n",
      "Epochs 897/1000 - Loss: 0.0017975098453462124\n",
      "--- 0.449s ---\n",
      "Epochs 898/1000 - Loss: 0.0017961901612579823\n",
      "--- 0.448s ---\n",
      "Epochs 899/1000 - Loss: 0.0017948728054761887\n",
      "--- 0.454s ---\n",
      "Epochs 900/1000 - Loss: 0.0017935576615855098\n",
      "--- 0.455s ---\n",
      "Epochs 901/1000 - Loss: 0.0017922453116625547\n",
      "--- 0.456s ---\n",
      "Epochs 902/1000 - Loss: 0.0017909350572153926\n",
      "--- 0.449s ---\n",
      "Epochs 903/1000 - Loss: 0.0017896274803206325\n",
      "--- 0.452s ---\n",
      "Epochs 904/1000 - Loss: 0.0017883218824863434\n",
      "--- 0.46s ---\n",
      "Epochs 905/1000 - Loss: 0.0017870189622044563\n",
      "--- 0.453s ---\n",
      "Epochs 906/1000 - Loss: 0.001785718253813684\n",
      "--- 0.439s ---\n",
      "Epochs 907/1000 - Loss: 0.0017844201065599918\n",
      "--- 0.455s ---\n",
      "Epochs 908/1000 - Loss: 0.0017831240547820926\n",
      "--- 0.452s ---\n",
      "Epochs 909/1000 - Loss: 0.0017818305641412735\n",
      "--- 0.449s ---\n",
      "Epochs 910/1000 - Loss: 0.0017805395182222128\n",
      "--- 0.455s ---\n",
      "Epochs 911/1000 - Loss: 0.0017792506841942668\n",
      "--- 0.449s ---\n",
      "Epochs 912/1000 - Loss: 0.0017779640620574355\n",
      "--- 0.461s ---\n",
      "Epochs 913/1000 - Loss: 0.0017766800010576844\n",
      "--- 0.453s ---\n",
      "Epochs 914/1000 - Loss: 0.0017753979191184044\n",
      "--- 0.457s ---\n",
      "Epochs 915/1000 - Loss: 0.0017741182819008827\n",
      "--- 0.449s ---\n",
      "Epochs 916/1000 - Loss: 0.0017728408565744758\n",
      "--- 0.453s ---\n",
      "Epochs 917/1000 - Loss: 0.0017715658759698272\n",
      "--- 0.452s ---\n",
      "Epochs 918/1000 - Loss: 0.0017702931072562933\n",
      "--- 0.46s ---\n",
      "Epochs 919/1000 - Loss: 0.0017690228996798396\n",
      "--- 0.465s ---\n",
      "Epochs 920/1000 - Loss: 0.0017677543219178915\n",
      "--- 0.447s ---\n",
      "Epochs 921/1000 - Loss: 0.001766488654538989\n",
      "--- 0.452s ---\n",
      "Epochs 922/1000 - Loss: 0.0017652250826358795\n",
      "--- 0.46s ---\n",
      "Epochs 923/1000 - Loss: 0.0017639636062085629\n",
      "--- 0.464s ---\n",
      "Epochs 924/1000 - Loss: 0.0017627044580876827\n",
      "--- 0.454s ---\n",
      "Epochs 925/1000 - Loss: 0.0017614476382732391\n",
      "--- 0.463s ---\n",
      "Epochs 926/1000 - Loss: 0.0017601929139345884\n",
      "--- 0.448s ---\n",
      "Epochs 927/1000 - Loss: 0.0017589405179023743\n",
      "--- 0.454s ---\n",
      "Epochs 928/1000 - Loss: 0.001757690217345953\n",
      "--- 0.448s ---\n",
      "Epochs 929/1000 - Loss: 0.0017564420122653246\n",
      "--- 0.453s ---\n",
      "Epochs 930/1000 - Loss: 0.0017551964847370982\n",
      "--- 0.449s ---\n",
      "Epochs 931/1000 - Loss: 0.0017539527034386992\n",
      "--- 0.456s ---\n",
      "Epochs 932/1000 - Loss: 0.0017527114832773805\n",
      "--- 0.451s ---\n",
      "Epochs 933/1000 - Loss: 0.0017514722421765327\n",
      "--- 0.452s ---\n",
      "Epochs 934/1000 - Loss: 0.001750235096551478\n",
      "--- 0.449s ---\n",
      "Epochs 935/1000 - Loss: 0.0017489999299868941\n",
      "--- 0.448s ---\n",
      "Epochs 936/1000 - Loss: 0.0017477674409747124\n",
      "--- 0.453s ---\n",
      "Epochs 937/1000 - Loss: 0.0017465369310230017\n",
      "--- 0.457s ---\n",
      "Epochs 938/1000 - Loss: 0.0017453086329624057\n",
      "--- 0.469s ---\n",
      "Epochs 939/1000 - Loss: 0.001744082197546959\n",
      "--- 0.451s ---\n",
      "Epochs 940/1000 - Loss: 0.0017428583232685924\n",
      "--- 0.454s ---\n",
      "Epochs 941/1000 - Loss: 0.001741636311635375\n",
      "--- 0.457s ---\n",
      "Epochs 942/1000 - Loss: 0.0017404165118932724\n",
      "--- 0.451s ---\n",
      "Epochs 943/1000 - Loss: 0.0017391986912116408\n",
      "--- 0.449s ---\n",
      "Epochs 944/1000 - Loss: 0.001737983082421124\n",
      "--- 0.451s ---\n",
      "Epochs 945/1000 - Loss: 0.0017367696855217218\n",
      "--- 0.453s ---\n",
      "Epochs 946/1000 - Loss: 0.0017355583840981126\n",
      "--- 0.451s ---\n",
      "Epochs 947/1000 - Loss: 0.0017343490617349744\n",
      "--- 0.451s ---\n",
      "Epochs 948/1000 - Loss: 0.001733141951262951\n",
      "--- 0.449s ---\n",
      "Epochs 949/1000 - Loss: 0.0017319368198513985\n",
      "--- 0.45s ---\n",
      "Epochs 950/1000 - Loss: 0.001730733783915639\n",
      "--- 0.451s ---\n",
      "Epochs 951/1000 - Loss: 0.001729532959870994\n",
      "--- 0.451s ---\n",
      "Epochs 952/1000 - Loss: 0.0017283342313021421\n",
      "--- 0.471s ---\n",
      "Epochs 953/1000 - Loss: 0.001727137598209083\n",
      "--- 0.451s ---\n",
      "Epochs 954/1000 - Loss: 0.0017259427113458514\n",
      "--- 0.45s ---\n",
      "Epochs 955/1000 - Loss: 0.0017247500363737345\n",
      "--- 0.445s ---\n",
      "Epochs 956/1000 - Loss: 0.0017235594568774104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.448s ---\n",
      "Epochs 957/1000 - Loss: 0.0017223708564415574\n",
      "--- 0.451s ---\n",
      "Epochs 958/1000 - Loss: 0.0017211843514814973\n",
      "--- 0.451s ---\n",
      "Epochs 959/1000 - Loss: 0.0017199998255819082\n",
      "--- 0.455s ---\n",
      "Epochs 960/1000 - Loss: 0.001718817395158112\n",
      "--- 0.457s ---\n",
      "Epochs 961/1000 - Loss: 0.0017176370602101088\n",
      "--- 0.457s ---\n",
      "Epochs 962/1000 - Loss: 0.0017164584714919329\n",
      "--- 0.451s ---\n",
      "Epochs 963/1000 - Loss: 0.0017152819782495499\n",
      "--- 0.456s ---\n",
      "Epochs 964/1000 - Loss: 0.0017141075804829597\n",
      "--- 0.449s ---\n",
      "Epochs 965/1000 - Loss: 0.0017129353946074843\n",
      "--- 0.458s ---\n",
      "Epochs 966/1000 - Loss: 0.0017117646057158709\n",
      "--- 0.444s ---\n",
      "Epochs 967/1000 - Loss: 0.0017105963779613376\n",
      "--- 0.452s ---\n",
      "Epochs 968/1000 - Loss: 0.0017094298964366317\n",
      "--- 0.456s ---\n",
      "Epochs 969/1000 - Loss: 0.0017082653939723969\n",
      "--- 0.461s ---\n",
      "Epochs 970/1000 - Loss: 0.0017071027541533113\n",
      "--- 0.453s ---\n",
      "Epochs 971/1000 - Loss: 0.0017059423262253404\n",
      "--- 0.456s ---\n",
      "Epochs 972/1000 - Loss: 0.0017047837609425187\n",
      "--- 0.45s ---\n",
      "Epochs 973/1000 - Loss: 0.0017036268254742026\n",
      "--- 0.451s ---\n",
      "Epochs 974/1000 - Loss: 0.001702472218312323\n",
      "--- 0.452s ---\n",
      "Epochs 975/1000 - Loss: 0.0017013195902109146\n",
      "--- 0.451s ---\n",
      "Epochs 976/1000 - Loss: 0.0017001685919240117\n",
      "--- 0.455s ---\n",
      "Epochs 977/1000 - Loss: 0.0016990199219435453\n",
      "--- 0.45s ---\n",
      "Epochs 978/1000 - Loss: 0.0016978728817775846\n",
      "--- 0.441s ---\n",
      "Epochs 979/1000 - Loss: 0.0016967278206720948\n",
      "--- 0.446s ---\n",
      "Epochs 980/1000 - Loss: 0.0016955847386270761\n",
      "--- 0.463s ---\n",
      "Epochs 981/1000 - Loss: 0.0016944435192272067\n",
      "--- 0.454s ---\n",
      "Epochs 982/1000 - Loss: 0.0016933040460571647\n",
      "--- 0.456s ---\n",
      "Epochs 983/1000 - Loss: 0.0016921666683629155\n",
      "--- 0.454s ---\n",
      "Epochs 984/1000 - Loss: 0.0016910310368984938\n",
      "--- 0.454s ---\n",
      "Epochs 985/1000 - Loss: 0.0016898976173251867\n",
      "--- 0.451s ---\n",
      "Epochs 986/1000 - Loss: 0.0016887658275663853\n",
      "--- 0.448s ---\n",
      "Epochs 987/1000 - Loss: 0.001687635900452733\n",
      "--- 0.449s ---\n",
      "Epochs 988/1000 - Loss: 0.0016865079523995519\n",
      "--- 0.451s ---\n",
      "Epochs 989/1000 - Loss: 0.00168538186699152\n",
      "--- 0.449s ---\n",
      "Epochs 990/1000 - Loss: 0.0016842572949826717\n",
      "--- 0.449s ---\n",
      "Epochs 991/1000 - Loss: 0.001683135167695582\n",
      "--- 0.451s ---\n",
      "Epochs 992/1000 - Loss: 0.0016820145538076758\n",
      "--- 0.445s ---\n",
      "Epochs 993/1000 - Loss: 0.0016808955697342753\n",
      "--- 0.463s ---\n",
      "Epochs 994/1000 - Loss: 0.0016797787975519896\n",
      "--- 0.448s ---\n",
      "Epochs 995/1000 - Loss: 0.001678663888014853\n",
      "--- 0.452s ---\n",
      "Epochs 996/1000 - Loss: 0.0016775507247075438\n",
      "--- 0.451s ---\n",
      "Epochs 997/1000 - Loss: 0.001676439307630062\n",
      "--- 0.449s ---\n",
      "Epochs 998/1000 - Loss: 0.0016753296367824078\n",
      "--- 0.452s ---\n",
      "Epochs 999/1000 - Loss: 0.0016742219449952245\n",
      "--- 0.451s ---\n",
      "Epochs 1000/1000 - Loss: 0.0016731161158531904\n",
      "--- 0.451s ---\n"
     ]
    }
   ],
   "source": [
    "recommender_system = RecommenderSystem(users_dim=113880+1, content_dim=4371+1, rank=32)\n",
    "recommender_system.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommmendations we are going to give will consist of twenty items. We select ten of the most popular. The other ten will be the most popular items per user, provided by the model just trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender_system_ratings = recommender_system.ratings.numpy()\n",
    "\n",
    "with open('output.csv','w') as f:\n",
    "    for i in range(113880+1):\n",
    "        my_predictions = recommender_system_ratings[i,:]\n",
    "        ix = list(np.argsort(my_predictions)[::-1])\n",
    "        r = list(metadata_train.query('account_id == {}'.format(i)).sort_values(by=['ratings'], ascending=False).loc[:,'content_id'].values)\n",
    "        r_ = [t for t in ix if t not in r][:10]\n",
    "        r__ = [t for t in top if t not in r+r_][:10]\n",
    "        f.write(str(i))\n",
    "        f.write(':')\n",
    "        f.write(str(r__+r_))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to calculate  the MAP (Mean Average Precision). We load the test information provided and perform the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.csv','r') as f:\n",
    "    test_csv = f.readlines()\n",
    "labels = []\n",
    "for line in test_csv:\n",
    "    label_line = []\n",
    "    for n in line.split(':')[1][1:-2].split(','):\n",
    "        if n!='':\n",
    "            label_line.append(int(n))\n",
    "    labels.append(label_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.csv','r') as f:\n",
    "    base_model_csv = f.readlines()\n",
    "preds = []\n",
    "for line in base_model_csv:\n",
    "    pred_line = []\n",
    "    for n in line.split(':')[1][1:-2].split(','):\n",
    "        pred_line.append(int(n))\n",
    "    preds.append(pred_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011896437213015325"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aps = [] \n",
    "for pred, label in zip(preds, labels):\n",
    "    n = len(pred) \n",
    "    arange = np.arange(n, dtype=np.int32) + 1. \n",
    "    rel_k = np.in1d(pred[:n], label) \n",
    "    tp = np.ones(rel_k.sum(), dtype=np.int32).cumsum() \n",
    "    denom = arange[rel_k] \n",
    "    if len(label)!=0:\n",
    "        ap = (tp / denom).sum() / len(label) \n",
    "    else:\n",
    "        ap = 0.\n",
    "    aps.append(ap)\n",
    "np.mean(aps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see, our model beats the baseline model provided. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
